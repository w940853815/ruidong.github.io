[{"title":"hexo搭建本博客","date":"2018-09-05T09:25:36.000Z","path":"2018/09/05/hexo博客搭建/","text":"安装(需要node,git) 1npm install -g hexo-cli 阅读hexo官方文档 https://hexo.io/zh-cn/docs/setup 完成建站，配置，熟悉hexo常用命令用法(init,new,generate,server,deploy) 使用主题 https://github.com/yscoder/hexo-theme-indigo 按照文档说明，换成hexo-theme-indigo主题 修改完配置，主要修改一些个人信息 创建文章 1hexo new post 文章标题 利用hexo发布到xxxx.github.io(hexo deploy)","tags":[{"name":"hexo","slug":"hexo","permalink":"https://w940853815.github.io/tags/hexo/"}]},{"title":"git ssh key 设置","date":"2018-09-05T08:48:44.000Z","path":"2018/09/05/git-ssh-key-设置/","text":"git ssh key 设置设置完成后，git pull,push等命令就不需要再输入用户名和密码了 生成公钥，私钥1ssh-keygen -t rsa -C &quot;邮箱地址&quot; 然后得到两个文件：私钥id_rsa和公钥id_rsa.pub 把公钥里面的内容复制到gitlab，github的ssh keys设置处 测试 1ssh -T git@主机ip 如果看到Hi后面是你的用户名，就说明成功了。 修改.git文件夹下config中的url 修改前123[remote &quot;origin&quot;] url = https://github.com/xxxx.git fetch = +refs/heads/*:refs/remotes/origin/* 修改后 123[remote &quot;origin&quot;] url = git@github.com:xxx.git fetch = +refs/heads/*:refs/remotes/origin/*","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"}]},{"title":"seafile磁盘空间满了解决办法","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/seafile磁盘空间满了解决办法/","text":"seafile磁盘空间满了解决办法磁盘扩容（虚拟机）参考：http://www.linuxidc.com/Linux/2012-07/65646.htm 物理机添加一块新的硬盘，原理相同 1fdisk -l :打印当前的磁盘分区表,可以看到新的磁盘加了进来 分区 1234fdisk /dev/sda “sda就是经过扩容的硬盘，为SCSI硬盘，IDE类型硬盘对应为hda，是对该硬盘进行操作n &quot; 命令n用于添加新分区&quot;p &quot; 选择创建主分区&quot;,然后选择分区编号3,4（主分区）w &quot;保存所有并退出，分区划分完毕&quot; 我们在这里是要添加一个新分区，即将扩容出来的那部分做成一个新分区，这样才能被操作系统挂载识别。 此时，fdisk会让你选择添加为逻辑分区呢（编号从5开始）还是主分区（编号1到4）。选择主分区吧，则键入p；选择逻辑分区键入l 此时，fdisk会让你选择主分区的编号，如果已经有了主分区sda1，sda2，那么编号就选3，即要创建的该分区为sda3.键入：3 此时，fdisk又会让你选择该分区的开始值这个就是分区的Start 值（start cylinder）；这里最好直接按回车，如果您输入了一个非默认的数字，会造成空间浪费 此时键入：w “保存所有并退出，分区划分完毕” 格式化 格式化该新添加的分区1mkfs -t ext3 /dev/sda3 磁盘挂载手动挂载，则键入：mount /dev/sda3 /home/work/ “表示将该新分区挂载到/home/work/这个目录下面” 开机自动挂载，则修改/etc/fstab文件，在这个文件里面添加一行：1/dev/sda4 /seafile-data ext3 defaults 0 1 创建符号链接 参考：https://bbs.seafile.com/t/seafile/71)(http://www.cnblogs.com/findumars/p/5747904.html)123cp -r /home/sysadmin/haiwen/seafile-data /seafile-data#当前目录 /home/sysadmin/haiwen/ln -s /seafile-data/ ./seafile-data 总结服务器上一定要慎用rm命令！！！！！！！","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"},{"name":"seafile","slug":"seafile","permalink":"https://w940853815.github.io/tags/seafile/"}]},{"title":"postgresql数据的导入和导出","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/postsql数据的导入和导出/","text":"数据导出PostgreSql在windows安装路径/bin目录下自带Pg_dump.exe执行程序 执行过程： 打开windows下的命令窗口：开始-&gt;cmd-&gt;安装数据库的目录-&gt;进入bin目录； 导出命令： 1pg_dump –h localhost –U db_username –p 5432 –d db_name –f “D:/test.dmp” 参数列表1234567-h：服务器地址；-p：端口号；-U：这里的“U”要大写；-d：数据库名称；-f：文件输出的目录和名称；可选参数-s, --schema-only 只转储模式,不包括数据（导出表结构） 按回车执行，会让输入口令（即数据库用户密码），输入即可，以上命令是输出数据库的全部对象，包含数据，对象(index，table，sequence，function等),但是不包含blob的大对象，如果需要导出大对象那么需要加上“-b”； 导入数据恢复数据：因为导出的是明文数据文件，一次使用psql命令，如：1psql -h localhost -U db_username -d db_name -f &quot;D:\\test.dmp&quot; 这边的-d后面的数据库名称即是需要导入的数据库。同样需要输入数据库密码。并且-d 后面数据库必须为已经存在的数据库补充 导出数据库：方式一：pg_dump -U postgres -f c:\\db.sql postgis方式二：pg_dump -U postgres postgis &gt; c:\\db.sql 导入数据库：方式一：psql -d postgis -f c:\\db.sql postgres 导出具体表：方式一：pg_dump -Upostgres -t mytable -f dump.sql postgres 导入具体表：方式一：psql -d postgis -f c:\\ dump.sql postgres","tags":[{"name":"数据库","slug":"数据库","permalink":"https://w940853815.github.io/tags/数据库/"}]},{"title":"ubuntu server 16 wifi连接设置","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/ubuntu-server-16-wifi连接设置/","text":"ubuntu server 16 wifi连接设置 安装驱动 12(需要安装aptitude)aptitude install firmware-iwlwifi 加载驱动 1modprobe iwl3945 安装需要的软件包 1apt-get install wireless-tools wpasupplicant 配置无线网络 1vi /etc/network/interfaces 123456auto wlan0iface wlan0 inet dhcppre-up ip link set wlan0 uppre-up iwconfig wlan0 essid ssidwpa-ssid ssidwpa-psk password 启用无线网线1ifup -v wlan0","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"}]},{"title":"ubuntu设置root密码，可ssh登陆","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/ubuntu设置root密码，可ssh登录/","text":"1 添加root用户密码1sudo passwd root 2 设置root用户可ssh登录1vi /etc/ssh/sshd_config 找到 1PermitRootLogin without-password 改为 1PermitRootLogin yes 重启ssh 1service ssh restart","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"}]},{"title":"爬取不同分辨率下的不同地图图片数据","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/爬取不同分辨率下的不同地图图片数据/","text":"爬取不同分辨率下的不同地图图片数据12345678910111213141516171819202122232425262728293031323334353637from math import *import urllibimport urllib2import requestsimport osurl_list=[]# 生成url,如/8/0/0.png,8/0/1.png.../8/0/255.png.../8/255/255.pngdef create_url(first,second): for y in range(int(pow(2,second))): for z in range(int(pow(2,second))): url_list.append(str(first)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos;) print str(first)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos; return url_list# 生成url对应的目录def create_dirs(url_list,base_filepath): for x in url_list: x = x.split(&apos;/&apos;) file_path = base_filepath + str(x[0]) + &apos;/&apos; + str(x[1])+&apos;/&apos; if not os.path.exists(file_path): print file_path os.makedirs(file_path)base_url = &apos;http://a.tile.openstreetmap.org/&apos;# 图片下载def download_png(url_list,filepath): for x in url_list: url = base_url + x urllib.urlretrieve(url, filename=&apos;d:/test/&apos;+x) # data = f.read() # with open(filepath + x, &quot;wb+&quot;) as code: # code.write(data)url_list=create_url(8,8)download_png(url_list,&apos;d:/test/&apos;)#create_dirs(url_list,&apos;d:/test/&apos;) 用法 先修改文件路径，分辨率等参数 然后先注释掉download_png函数调用，先调用create_dirs函数创建目录，然后取消注释开始下载图片 采用多进程爬取，并处理网络带来的IOError1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495from math import *import urllibimport urllib2import requestsimport osfrom exceptions import IOErrorimport loggingimport logginglogging.basicConfig(level=logging.WARNING, format=&apos;%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s&apos;, datefmt=&apos;%a, %d %b %Y %H:%M:%S&apos;, filename=&apos;myapp.log&apos;, filemode=&apos;w&apos;)url_list=[]filepath = &apos;d:/test/&apos;base_url = &apos;http://a.tile.openstreetmap.org/&apos;def create_url(start,rate): for y in range(start,int(pow(2,rate))): for z in range(int(pow(2,rate))): url_list.append(str(rate)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos;) logging.warning(str(rate)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos;) return url_listdef create_dirs(url_list,base_filepath): for x in url_list: x = x.split(&apos;/&apos;) file_path = base_filepath + str(x[0]) + &apos;/&apos; + str(x[1])+&apos;/&apos; if not os.path.exists(file_path): logging.warning(file_path) os.makedirs(file_path)def download_png(url_list,filepath): for x in url_list: try: url = base_url + x print url logging.warning(url) urllib.urlretrieve(url, filename=filepath+x) except IOError as serr: logging.error(serr) time.sleep(180) urllib.urlretrieve(url, filename=filepath+x)import multiprocessingimport timedef worker_1(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_2(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_3(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_4(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_5(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_5(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)if __name__ == &quot;__main__&quot;: p1 = multiprocessing.Process(target = worker_1, args = (630,10)) p2 = multiprocessing.Process(target = worker_2, args = (700,10)) p3 = multiprocessing.Process(target = worker_3, args = (800,10)) p4 = multiprocessing.Process(target = worker_4, args = (900, 10)) p5 = multiprocessing.Process(target = worker_5, args = (1000, 10)) p1.start() p2.start() p3.start() p4.start() p5.start()","tags":[{"name":"爬虫","slug":"爬虫","permalink":"https://w940853815.github.io/tags/爬虫/"},{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]}]