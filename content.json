[{"title":"2019已读书籍(6-12月)","date":"2019-12-30T02:21:10.930Z","path":"2019/12/30/2019已读书籍/","text":"6月霍乱时期的爱情（加西亚·马尔克斯） 未来世界的幸存者（阮一峰） 富爸爸，穷爸爸（罗伯特・T・清崎 / 莎伦・L・莱希特） 前方的路（阮一峰） 动物农场（ 乔治·奥威尔） 7月经济学原理（N·格里高利·曼昆） 万历十五年(黄仁宇) 1984( 乔治·奥威尔) 8月黑客与画家（保罗·格雷厄姆） 追风筝的人(卡勒德·胡赛尼) 送你一颗子弹(刘瑜) 房思琪的初恋乐园(林奕含) 9月殡葬人手记（托马斯·林奇） 断舍离(山下英子) 那些伤不起的年轻人(二白) 愿所有相遇，都恰逢其时(DTT) 10月Redis实战（Redis in action）（ Josiah L. Carlson） 如何阅读一本书(莫提默·J. 艾德勒 / 查尔斯·范多伦) 宿命(东野圭吾) 变身(东野圭吾) 11月 ###树上的男爵（卡尔维诺） JavaScript高级程序设计（第3版）(尼古拉斯·泽卡斯) 他们最幸福(大冰) 柑橘与柠檬啊(麦克·莫波格) 12月全球通史（斯塔夫里阿诺斯） 牛虻( 伏尼契) 皮囊( 蔡崇达) 寂寞的游戏( 袁哲生)","tags":[{"name":"书籍","slug":"书籍","permalink":"https://w940853815.github.io/tags/书籍/"}]},{"title":"celery autoreload when code change","date":"2019-12-13T08:52:42.577Z","path":"2019/12/13/代码改动celery自动重启/","text":"当调试celery相关的代码时，每次改完代码，都需要重启celery代码才可以生效，本文的目的就是当代码发生改动，celery可以自动重启,示例代码task.py如下（注：请根据自己的业务逻辑自行修改）12345678910111213from celery import Celeryapp=Celery(\"tasks\", backend=\"redis://127.0.0.1:6379/1, broker=\"redis://127.0.0.1:6379/1\")@app.taskdef add(x,y): return x+y if __name__ == \"__main__\": from werkzeug._reloader import run_with_reloader # 开发时可以直接运行python tasks.py 当前目录下文件改动时，celery会自动重启 run_with_reloader(app.worker_main) 示例代码主要用到了werkzeug库的run_with_reloader函数实现了celery自动重启","tags":[{"name":"celery","slug":"celery","permalink":"https://w940853815.github.io/tags/celery/"}]},{"title":"解决es查询索引不存在导致404问题","date":"2019-12-06T08:37:28.660Z","path":"2019/12/06/解决es查询索引不存在导致404问题/","text":"问题 但查询http://localhost:9100/index1,index2,index3/_search某个索引不存在时，就会出错 1elasticsearch.exceptions.NotFoundError: TransportError(404, 'index_not_found_exception', 'no such index') 解决办法 项目使用的是elasticsearch库,在使用search函数时，添加一个param参数，代码如下 1234567from elasticsearch import Elasticsearches = Elasticsearch(api, http_auth=http_auth)# body,index分别查询体，索引es_index='index1,index2,index3'body=&#123;&#125;params = &#123;\"ignore_unavailable\": \"true\"&#125;result = es.search(index=es_index, body=body, params=params) 这样就会忽略索引不存在的问题，不会报404了 如果使用requests库或者类似postman接口请求工具请求es数据时，可以在url后加?ignore_unavailable=true参数即可忽略索引不存在错误 1http://localhost:9100/index1,index2,index3/_search?ignore_unavailable=true","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://w940853815.github.io/tags/ElasticSearch/"}]},{"title":"Python求某个数值所在的区间","date":"2019-12-02T02:01:02.451Z","path":"2019/12/02/Python求某个数值所在的区间/","text":"求一个数值在哪个区间，可以使用python-intervals来实现 安装 1pip install python-interval 示例代码12345678910111213import intervals as IREP_RES_DES_MAP = I.IntervalDict()REP_RES_DES_MAP_CONFIG = &#123; I.closedopen(-7, 0): 'A', I.closedopen(-14, -7): 'B', I.closedopen(-I.inf, -14): 'C', I.closedopen(0, 2): 'D', I.closedopen(2, 3): 'E', I.closedopen(3, I.inf): 'F',&#125;for key, value in REP_RES_DES_MAP_CONFIG.items(): REP_RES_DES_MAP[key] = value 这样的话，比如REP_RES_DES_MAP[-10]得到的值就会是’B’，不用写大量的if,elif,else作判断，其中I.inf表示无穷大，-I.inf表示负无穷大","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]},{"title":"jenkins初步使用","date":"2019-11-04T02:27:54.796Z","path":"2019/11/04/jenkins初步使用/","text":"之前完成一个功能或修复一个bug，测试环境每次都是登录的服务器，手动执行命令去更新代码，重启服务，一天可能会进行好几次这样的操作，所以想要使用jenkins来实现部署自动化 安装安装环境123CentOS7jdk 1.8Jenkins 2.190.2 安装步骤安装按照官网文档应该就可以了，官方文档链接，本文下载的是war包，执行以下命令启动jenkins 1java -jar jenkins.war --daemon --httpPort=8080 --logfile=/root/jenkins.log 加–daemon参数，可以让Jenkins后台执行 配置jenkins初始化问题安装初始化的插件时，可能会遇到配置代理的问题，在浏览器输入{jenkins服务地址/pluginManager/advanced ​ 将图中的参数https换成http,然后再回到初始话插件的页面，如果还是遇到之前的问题，多试几次就可以了，笔者也是试了很多次才安装好 配置ssh远程执行命令因为jenkins运行的机器和构建的机器不在同一台机器，所以这里用到了jenkins的插件远程执行build命令 在jenkins-&gt;插件管理中安装 SSH plugin插件和Coding Webhook Plugin 配置凭据 在jenkins-&gt;凭据里新建一个凭据，这里主要需要填构建机器私钥，即cat ~/.ssh/id_rsa中的内容，填完保存 在Manager Jenkins-&gt;Configure System-&gt;SSH remote hosts中新建一个配置,填好保存 然后新建一个任务,主要设置两个地方，coding这里WebHook令牌需要在coding里设置一下（需要管理员权限） 在构建选项中选择Execute shell script on remote host using ssh,选择之前配置的机器和填需要之行的命令,填完保存就可以了 到这里基本完成，可以自动化构建系统了，还是方便了很多","tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://w940853815.github.io/tags/jenkins/"},{"name":"ci","slug":"ci","permalink":"https://w940853815.github.io/tags/ci/"}]},{"title":"ubuntu16搭建本地apt源","date":"2019-10-24T03:33:58.626Z","path":"2019/10/24/ubuntu16搭建本地apt源/","text":"本文服务器环境Ubuntu 16.04.3 LTS,因为一些特殊业务原因，有些服务器需不能上外网，服务器安装一些软件包特别麻烦，需要下载软件的deb和软件依赖的deb包，有时下载不全deb包，安装软件就会失败，所以需要在内网环境搭建一个apt源，这样就可以使用apt自动解决一些软件包的依赖。 安装apt-mirror1apt-get install apt-mirror 配置mirror.list文件可根据服务器网络环境选择合适的下载线程数和apt镜像源,因为服务器在清华，所以选择清华镜像源（150G文件一个小时就同步完了）1234567891011# 镜像文件下载地址set base_path /data/apt-mirror# 下载线程数set nthreads 20set _tilde 0deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverseclean http://mirrors.tuna.tsinghua.edu.cn/ubuntu 文件配置完成后，执行apt-mirror开始同步，因为同步时间比较长，笔者使用tmux,建立一个session，然后执行命令，或者使用nohup命令放到后台执行 配置nginx（配置HTTP访问）更改/etc/nging/nginx.conf文件，加以下配置123456789101112server &#123; listen 80; # 显示目录 autoindex on; location / &#123; index index.html index.htm; # 这里填写镜像保存位置 root /data/apt-mirror; &#125; access_log /var/log/nginx/localhost.log;&#125; 更改完配置，先测试配置，如果测试通过，则重新加载nginx配置文件 12nginx -tnginx -s reload 客户端配置编辑/etc/apt/source.list文件（可以先备份一下），ip和端口级网站目录结构需要根据自己的配置修改 1234deb [arch=amd64] http://127.0.0.1:81/mirror/mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiversedeb [arch=amd64] http://127.0.0.1:81/mirror/mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiversedeb [arch=amd64] http://127.0.0.1:81/mirror/mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiversedeb [arch=amd64] http://127.0.0.1:81/mirror/mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse 以上客户端配置也多添加了[arch=amd64]，用于指定架构，否则会出现 123Err http://127.0.0.1:81 trusty/main i386 Packages 404 Not Found... 最后执行,更新成功就可以安装需要的软件了 1apt-get update","tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://w940853815.github.io/tags/ubuntu/"},{"name":"apt","slug":"apt","permalink":"https://w940853815.github.io/tags/apt/"}]},{"title":"后面要做的事情","date":"2019-10-22T10:44:13.338Z","path":"2019/10/22/立flag/","text":"好久没刷leetcode了，觉得自己刷起来很吃力，去看算法书，结果算法书也读着也吃劲，结果就没再刷了，今天看了一位大佬的博客，发现进大厂都是在考算法，觉着应该还是要多学习算法，不能让自己待在舒适区，自己还年轻，趁着年轻，还学的动，不能每天只是curd 给自己定个刷算法计划： 每周至少三个算法，无上限 算法书继续读（一周一章？）","tags":[{"name":"idea","slug":"idea","permalink":"https://w940853815.github.io/tags/idea/"},{"name":"leetcode","slug":"leetcode","permalink":"https://w940853815.github.io/tags/leetcode/"}]},{"title":"ERROR-No-compiler-is-provided-in-this-environment.-Perhaps-you-are-running-on-a-JRE-rather-than-a-JDK","date":"2019-10-21T10:34:51.182Z","path":"2019/10/21/[ERROR]No_compiler_is_provided_in_this_environment_Perhaps_you_are_running_on_a_JRE_rather_than_a_JDK/","text":"mvn install时报错No compiler is provided in this environment. Perhaps you are running on a JRE rather than a JDK?1234567root@ruidong:~/dcm4che# mvn -vApache Maven 3.3.9Maven home: /usr/share/mavenJava version: 1.8.0_222, vendor: Private BuildJava home: /usr/lib/jvm/java-8-openjdk-amd64/jreDefault locale: en_US, platform encoding: UTF-8OS name: \"linux\", version: \"4.15.0-58-generic\", arch: \"amd64\", family: \"unix\" mvn -v显示Java home后带jre，我以为我JAVA_HOME配置错了，改了下~/.bashrc文件重新配置了JAVA_HOME,结果并未解决问题，问题jdk版本问题，机器装的是java-8-openjdk-amd64,参考链接，重新安装jdk错误解决（系统为ubtuntu16） 1sudo apt-get install openjdk-8-jdk","tags":[{"name":"java","slug":"java","permalink":"https://w940853815.github.io/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://w940853815.github.io/tags/maven/"}]},{"title":"记一次服务器漏洞处理过程（如何删除jar中的文件）","date":"2019-09-10T10:16:57.890Z","path":"2019/09/10/记一次服务器漏洞处理过程/","text":"今天收到邮件，漏洞摘要如下 意思存在一下网站目录下一些markdown文件，漏洞原因：在目录中发现文档文件(例如: readme.txt, changelog.txt, …) 文档文件中可能包含当 前网站程序使用的名称及版本信息，可以帮助 恶意攻击者识别网站应用并攻击网站，应该从 线上服务器删除这些文件。 看到这个以后，想着直接找到文件所在目录，删除就好，但处理过程并没有这么顺利 先查找服务器目录以md为扩展名的文件，结果并未找到 12root@67e088ad8f62:/opt/guacamole# find / | grep -i *.mdroot@67e088ad8f62:/opt/guacamole# 又以jquery，angular等字段查找，发现jar包名和url路径十分相似，推测这些md文件是从jar获得的，所以问了下java的同学同事，确实会这样 1234567root@67e088ad8f62:/opt/guacamole# find / | grep -i jquery/usr/local/tomcat/webapps/guacamole_bak/WEB-INF/lib/jquery-3.3.1.jar/usr/local/tomcat/webapps/guacamole_bak/META-INF/bundled/jquery-3.3.1/usr/local/tomcat/webapps/guacamole_bak/META-INF/bundled/jquery-3.3.1/LICENSE.txt/usr/local/tomcat/webapps/guacamole/WEB-INF/lib/jquery-3.3.1.jar/usr/local/tomcat/webapps/guacamole/META-INF/bundled/jquery-3.3.1/usr/local/tomcat/webapps/guacamole/META-INF/bundled/jquery-3.3.1/LICENSE.txt 想到两个解决办法：a.直接删除jar包中的文件。b.修改tomcat配置，配置文件访问规则，以md为扩展名的文件返回404。b方法找了一会，没发现有这样的配置，所以开始使用a方法，a方法这里使用到jar，zip工具 列出jar包中文件内容 用法: jar {ctxui}[vfmn0PMe] [jar-file] [manifest-file] [entry-point] [-C dir] files …选项: -t 列出档案目录 -v 在标准输出中生成详细输出 -f 指定档案文件名 123456789101112131415➜ lib# jar -tvf angular-module-shim-0.0.4.jar 0 Mon Nov 28 19:02:36 CST 2016 META-INF/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/maven/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/maven/org.webjars.bower/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/maven/org.webjars.bower/angular-module-shim/ 1613 Mon Nov 28 19:02:36 CST 2016 META-INF/maven/org.webjars.bower/angular-module-shim/pom.xml 105 Mon Nov 28 19:02:36 CST 2016 META-INF/maven/org.webjars.bower/angular-module-shim/pom.properties 0 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/0.0.4/ 1078 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/0.0.4/LICENSE 1104 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/0.0.4/README.md 774 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/0.0.4/angular-module-shim.js 543 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/0.0.4/bower.json 找到jar包中包含README.md文件，文件路径和url中一致，所以删除jar中的README.md文件，用到zip命令,不需要解压jar包删除文件后再打成jar包 zipzip [-options] [-b path] [-t mmddyyyy] [-n suffixes] [zipfile list] [-xi list] -d delete entries in zipfile -m move into zipfile (delete OS files) 12➜ lib# zip -d angular-module-shim-0.0.4.jar \"META-INF/resources/webjars/angular-module-shim/0.0.4/README.md\"deleting: META-INF/resources/webjars/angular-module-shim/0.0.4/README.md 最后将处理过的jar上传到服务器，进行替换，发现大部分链接都访问不到，返回404了，但还有3个链接还是返回README.md，确认了好几次jar包已经没有README.md文件，折腾好久，最后想到是不是存在缓存，这里在原先url地址后加 ?a=1,发现链接返回404了，原来是本地浏览器缓存，清掉缓存后，有漏洞的文件都已经处理了，问题解决","tags":[{"name":"java","slug":"java","permalink":"https://w940853815.github.io/tags/java/"},{"name":"local cache","slug":"local-cache","permalink":"https://w940853815.github.io/tags/local-cache/"}]},{"title":"python使用cProfile对脚本进行性能分析","date":"2019-09-05T05:47:24.846Z","path":"2019/09/05/python使用cProfile对脚本进行性能分析/","text":"写者要从oracle数据库导出一些长文本字段的数据，但效率不是太高，导出十多条数据需要2-3分钟，所以想对脚本进行一下性能分析，看脚本导出慢在了哪里，生成的图像文件如下 最后发现时间都花在了oracle查询fetchall函数上，所以后面是因为查询的sql没有使用索引的字段去查，会很慢，使用索引的字段去查，效率提升了 十几倍 这里使用的是 gprof2dot, 可以看到调用次数, 占用时间和百分比信息的图像，比较直观 安装 mac 1brew install gprof2dot Debian/Ubuntu users1apt-get install graphviz 生成图像文件12python3 -m cProfile -o output.pstat test.pygprof2dot -f pstats output.pstat | dot -Tpng -o output.png 执行完，在脚本的目录就会生成图像文件了","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"},{"name":"数据库","slug":"数据库","permalink":"https://w940853815.github.io/tags/数据库/"},{"name":"性能分析","slug":"性能分析","permalink":"https://w940853815.github.io/tags/性能分析/"}]},{"title":"es年龄分段统计","date":"2019-08-28T08:19:39.138Z","path":"2019/08/28/es年龄分段统计/","text":"前端最终效果展示 这里需要统计不同年龄段的人数，以10为间隔1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556\"age_ranges\": &#123; \"range\": &#123; \"field\": \"VISIT_AGE\", \"ranges\": [&#123; \"key\": \"0-10\", \"from\": 0, \"to\": 10 &#125;, &#123; \"key\": \"10-20\", \"from\": 10, \"to\": 20 &#125;, &#123; \"key\": \"20-30\", \"from\": 20, \"to\": 30 &#125;, &#123; \"key\": \"30-40\", \"from\": 30, \"to\": 40 &#125;, &#123; \"key\": \"40-50\", \"from\": 40, \"to\": 50 &#125;, &#123; \"key\": \"50-60\", \"from\": 50, \"to\": 60 &#125;, &#123; \"key\": \"60-70\", \"from\": 60, \"to\": 70 &#125;, &#123; \"key\": \"70-80\", \"from\": 70, \"to\": 80 &#125;, &#123; \"key\": \"80-90\", \"from\": 80, \"to\": 90 &#125;, &#123; \"key\": \"90-100\", \"from\": 90, \"to\": 100 &#125; ] &#125;&#125; 查询语句中一开始ranges没有key键，只有{“”from”: 0,”to”: 10”}，这样查询的结果会转成浮点数，如下 1&#123;'buckets': [&#123;'key': '0.0-10.0', 'from': 0.0, 'to': 10.0, 'doc_count': 0&#125;, &#123;'key': '10.0-20.0', 'from': 10.0, 'to': 20.0, 'doc_count': 0&#125;, &#123;'key': '21.0-30.0', 'from': 21.0, 'to': 30.0, 'doc_count': 1&#125;, &#123;'key': '31.0-40.0', 'from': 31.0, 'to': 40.0, 'doc_count': 4&#125;, &#123;'key': '41.0-50.0', 'from': 41.0, 'to': 50.0, 'doc_count': 5&#125;, &#123;'key': '51.0-60.0', 'from': 51.0, 'to': 60.0, 'doc_count': 16&#125;, &#123;'key': '61.0-70.0', 'from': 61.0, 'to': 70.0, 'doc_count': 29&#125;, &#123;'key': '71.0-80.0', 'from': 71.0, 'to': 80.0, 'doc_count': 12&#125;, &#123;'key': '80.0-90.0', 'from': 80.0, 'to': 90.0, 'doc_count': 3&#125;, &#123;'key': '91.0-100.0', 'from': 91.0, 'to': 100.0, 'doc_count': 0&#125;]&#125; 加上key就可以指定返回的key了","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://w940853815.github.io/tags/ElasticSearch/"}]},{"title":"断舍离读书笔记","date":"2019-08-28T07:21:39.838Z","path":"2019/08/28/断舍离/","text":"以自我为中心挑选物品，而不是以物品为中心 一旦通过断舍离提升了自我形象，那么别人就会自然而然地觉得”他生活得那么精致，可不能随便拿个粗陋的东西送他就了事了”。慢慢地，你就会感觉到，周围人对待自己的态度发生了变化。可见，这种筛选物品的工作，也具有改变自己与他人关系的力量","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://w940853815.github.io/tags/读书笔记/"}]},{"title":"flask_restfule接收多个文件","date":"2019-08-21T03:28:36.000Z","path":"2019/08/21/flask_restful同时接收多个文件/","text":"添加action=’append’即可接受多个文件 12345678910111213@rest_resourceclass Uploads(BaseResource): endpoints = ['/uploads'] @token_auth.login_required def post(self, *args, **kwargs): parser = reqparse.RequestParser() parser.add_argument('file', type=werkzeug.FileStorage,location='files', action='append') args = parser.parse_args() files = args.file # type(files) &gt;&gt;&gt;list for file in files: file.save('file_path') return &#123;'msg': '文件上传成功！'&#125;","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"},{"name":"flask","slug":"flask","permalink":"https://w940853815.github.io/tags/flask/"},{"name":"flask-restful","slug":"flask-restful","permalink":"https://w940853815.github.io/tags/flask-restful/"}]},{"title":"boot failed nfs,welcome to emergency mode","date":"2019-06-20T07:55:12.000Z","path":"2019/06/20/nfs_boot_faild/","text":"问题：机房服务器断电进行消防检查，检查完后服务器远程登录不了去机房查看服务器，服务器启动时出现了 welcome to emergency mode. ...... journalctl -xb... ..... Press enter for maintenance (or type Control-D to continue): --- Ctrl+d继续启动服务器。 按下Ctrl+d 成功启动 因为服务器使用nfs挂载了网络存储，猜测存储服务器还未完全启动，服务器就去挂载网络存储，会找不到，所以服务器出现了上述情况 解决方案1UUID=d9a2b784-4579-4d89-8713-4b7d6b00742b /bigdata ext4 defaults,x-systemd.device-timeout=3 0 0 在/etc/fstab文件中添加了一个选项,x-systemd.device-timeout=3参考) 设置 x-systemd.device-timeout=# 参数，设置超时时间，以防止网络资源不能访问的时候浪费时间 使用以下命令检查fstab是否存在内容错误 1` mount -fav` -f, –fake dry run; skip the mount(2) syscall 表示这只是测试, 并不会真的安装 -a, –all mount all filesystems mentioned in fstab 表示测试所有 /etc/fstab 中的内容 -v, –verbose say what is being done 表示显示尽可能多的 log","tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://w940853815.github.io/tags/ubuntu/"}]},{"title":"* No PostgreSQL clusters exist; see 'man pg_createcluster'","date":"2018-09-21T08:55:12.000Z","path":"2018/09/21/No-PostgreSQL-clusters-exist-see-man-pg-createcluster/","text":"Ubuntu14.04 PostgreSQL(9.3)卸载又重装,启动postgresql时会报No PostgreSQL clusters exist; see ‘’man pg_createcluster”错误，解决办法: 1234sudo pg_createcluster 9.3 main --start# 如果是9.5版本sudo pg_createcluster 9.5 main --startsudo service postgresql restart","tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://w940853815.github.io/tags/postgresql/"},{"name":"数据库","slug":"数据库","permalink":"https://w940853815.github.io/tags/数据库/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://w940853815.github.io/tags/ubuntu/"}]},{"title":".gitignore规则不生效","date":"2018-09-21T08:35:17.000Z","path":"2018/09/21/gitignore规则不生效/","text":"gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。 解决方法就是先把本地缓存删除（改变成未track状态），然后再提交: 1git rm -r --cached .","tags":[{"name":"git","slug":"git","permalink":"https://w940853815.github.io/tags/git/"}]},{"title":"TypeError: the JSON object must be str, not 'bytes'","date":"2018-09-21T08:28:42.000Z","path":"2018/09/21/TypeError-the-JSON-object-must-be-str-not-bytes/","text":"res类型是bytes时 1data = json.loads(res) 会报终端错误 1TypeError: the JSON object must be str, not 'bytes' 解决办法 1data = json.loads(res.decode('utf-8')) 好像这个错误和python版本有关系，python3.6不需要decode不会报错，python3.5会报这个错误","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]},{"title":"ModuleNotFoundError: No module named 'kombu.async'","date":"2018-09-21T08:24:51.000Z","path":"2018/09/21/ModuleNotFoundError-No-module-named-kombu-async/","text":"启动celery时报错ModuleNotFoundError: No module named ‘kombu.async’ 解决办法 1pip install -U celery==4.1.1 详情参考issuses #4760","tags":[{"name":"celery","slug":"celery","permalink":"https://w940853815.github.io/tags/celery/"},{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]},{"title":"postgres ERROR permission denied to create database 解决方法","date":"2018-09-13T06:35:52.000Z","path":"2018/09/13/postgres-ERROR-permission-denied-to-create-database-解决方法/","text":"ERROR: permission denied to create database 在mac os x上用brew安装postgresql时 ，它不像linux系统上会默认创建一个postgres的系统用户,可以打开数据库控制台创建数据库 123➜ dmp git:(master) ✗ psql -d postgrespostgres=# create database test;CREATE DATABASE","tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://w940853815.github.io/tags/postgresql/"},{"name":"数据库","slug":"数据库","permalink":"https://w940853815.github.io/tags/数据库/"}]},{"title":"flask_sqlalchemy使用","date":"2018-09-11T14:19:36.000Z","path":"2018/09/11/flask-sqlalchemy使用/","text":"postgresql—flask-sqlalchemy字段对应 Postgresql Flask-sqlachemy varchar2 （有长度） db.Column(db.String(50)) Init db.Column(db.Integer) timestamp db.Column(db.DateTime) varchar2 （无长度） db.Column(db.String) 主键默认使用uuid 1id = db.Column(db.String(64), primary_key=True) 字段不为空 1name = db.Column(db.String(50), nullable=False) 设置外键 1org_id = db.Column(db.String(64), db.ForeignKey('tb_org.org_id')) 创建索引 1name = db.Column(db.String(50), index=True) #注意： 1id = db.Column(db.String(64), primary_key=True, default=uuid.uuid4()) 这样默认值会再添加完一条数据，再次添加一条数据时，会主键id已存在，所以不要采取这种方式，应在插入时生成一个新的uuid，例如： 1tb_u = tb_user(user_id=uuid.uuid4(),user_phone=phone)","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"},{"name":"flask","slug":"flask","permalink":"https://w940853815.github.io/tags/flask/"},{"name":"flask-sqlalchemy","slug":"flask-sqlalchemy","permalink":"https://w940853815.github.io/tags/flask-sqlalchemy/"}]},{"title":"celery使用","date":"2018-09-07T03:58:12.000Z","path":"2018/09/07/celery任务状态/","text":"Celery任务状态 PENDING-&gt;STARTED-&gt;SUCCESS/FAILD “STARTED”状态是一个特殊状态,当task_trace_started配置被设置为True或者@task(track_started=True)选项被设置时才会有出现STARTED状态 PENDING”状态实际上并不是一个记录状态，它是任何未知id的任务的默认状态，下面的例子中会出现这一状态： 123from proj.celery import appres=app.AsyncResult('this-id-does-not-exist')res.state'PENDING' cekery key erro ‘async’错误解决方法 1pip install -U \"celery[redis]\" supervisor配置celery 12345678910111213141516[program:celery]command=/usr/local/bin/celery worker -A tasks --loglevel=infodirectory=&#123;tasks.py文件所在目录&#125;user=rootnumprocs=1;redirect_stderr=true ; redirect proc stderr to stdout (default false)stdout_logfile=/var/log/supervisord/celery.logstderr_logfile=/var/log/supervisord/celery.logautostart=trueautorestart=truestartsecs=10stopwaitsecs = 600killasgroup=truepriority=998stdout_logfile_maxbytes = 20MBstdoiut_logfile_backups = 20","tags":[{"name":"celery","slug":"celery","permalink":"https://w940853815.github.io/tags/celery/"},{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]},{"title":"iview modal控制关闭","date":"2018-09-07T03:44:27.000Z","path":"2018/09/07/iview-modal控制关闭/","text":"使用 iview 的 Modal对话框实现单击确定的时候不直接关闭对话框，而是经过一些判断，满足自己的条件的时候再关闭对话框 使用iview的 slot 自定义样式实现，经过一些业务逻辑判断，可控制modal显示关闭 1234&lt;divslot=&quot;footer&quot;&gt; &lt;Buttontype=&quot;text&quot;size=&quot;large&quot; @click=&quot;modalCancel&quot;&gt;取消Button&gt; &lt;Buttontype=&quot;primary&quot;size=&quot;large&quot; @click=&quot;modalOk&quot;&gt;确定Button&gt;&lt;div&gt;","tags":[{"name":"vue","slug":"vue","permalink":"https://w940853815.github.io/tags/vue/"},{"name":"iview","slug":"iview","permalink":"https://w940853815.github.io/tags/iview/"}]},{"title":"python3基础数据知识整理","date":"2018-09-06T09:04:34.000Z","path":"2018/09/06/python基础数据知识整理/","text":"列表(list)) 字典(dict)) 列表(list)123456789101112# 两个列表相加[1, 2, 3] + [4, 5, 6]# 判断某一元素是否在列表中3 in [1, 2, 3]# 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表）list.extend(seq)# 从列表中找出某个值第一个匹配项的索引位置list.index(obj)# 指定位置将对象插入列表list.insert(index, obj)# 移除列表中某个值的第一个匹配项list.remove(obj) 字典(dict)123456789101112131415161718192021222324252627282930313233343536373839404142434445# dict键必须不可变，所以可以用数字，字符串或元组充当，所以用列表就不行# 删除键是'Name'的条目del dict['Name']# 清空词典所有条目dict.clear()# 删除词典del dict# 计算字典元素个数，即键的总数len(dict)# 创建一个新字典，以序列 seq 中元素做字典的键，val 为字典所有键对应的初始值dict.fromkeys(seq[, val])In [75]: d= dict.fromkeys([1,2,3],['a','b','c'])In [76]: dOut[76]: &#123;1: ['a', 'b', 'c'], 2: ['a', 'b', 'c'], 3: ['a', 'b', 'c']&#125;# 返回指定键的值，如果值不在字典中返回default值dict.get(key, default=None)# 以列表返回一个字典所有的键dict.keys()In [78]: d.keys()Out[78]: dict_keys([1, 2, 3])In [79]: type(d.keys())Out[79]: dict_keysIn [80]: list(d.keys())Out[80]: [1, 2, 3]# 以列表返回字典中的所有值dict.values()In [81]: d.values()Out[81]: dict_values([['a', 'b', 'c'], ['a', 'b', 'c'], ['a', 'b', 'c']])# 删除字典给定键 key 所对应的值，返回值为被删除的值。key值必须给出。 否则，返回default值。pop(key[,default])In [83]: d.pop(1)Out[83]: ['a', 'b', 'c']# 随机返回并删除字典中的一对键和值。popitem()In [84]: d.popitem()Out[84]: (3, ['a', 'b', 'c']) 未完待续…","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]},{"title":"hexo搭建本博客","date":"2018-09-05T09:25:36.000Z","path":"2018/09/05/hexo博客搭建/","text":"安装(需要node,git) 1npm install -g hexo-cli 阅读hexo官方文档 https://hexo.io/zh-cn/docs/setup 完成建站，配置，熟悉hexo常用命令用法(init,new,generate,server,deploy) 使用主题 https://github.com/yscoder/hexo-theme-indigo 按照文档说明，换成hexo-theme-indigo主题 修改完配置，主要修改一些个人信息 创建文章 1hexo new post 文章标题 利用hexo发布到xxxx.github.io(hexo deploy) 使用gitment支持评论123456&#123;HEXO_ROOT&#125;/themes/indigo/_config.yml修改配置gitment: owner: xxx # github用户名 repo: xxx.github.io # 不加https client_id: xxx client_secret: xxx 使用gitment插件中间遇到的问题 404 not foundrepo填错，或者owner不对 422 错误向github提交的url参数超过了限制，解决办法http://hheszy.com/2018/03/19/hexo-next-validation-failed-%E6%8A%A5%E9%94%99gitment%E9%85%8D%E7%BD%AEgitment-swig/","tags":[{"name":"hexo","slug":"hexo","permalink":"https://w940853815.github.io/tags/hexo/"}]},{"title":"git ssh key 设置","date":"2018-09-05T08:48:44.000Z","path":"2018/09/05/git-ssh-key-设置/","text":"git ssh key 设置设置完成后，git pull,push等命令就不需要再输入用户名和密码了 生成公钥，私钥1ssh-keygen -t rsa -C &quot;邮箱地址&quot; 然后得到两个文件：私钥id_rsa和公钥id_rsa.pub 把公钥里面的内容复制到gitlab，github的ssh keys设置处 测试 1ssh -T git@主机ip 如果看到Hi后面是你的用户名，就说明成功了。 修改.git文件夹下config中的url 修改前123[remote &quot;origin&quot;] url = https://github.com/xxxx.git fetch = +refs/heads/*:refs/remotes/origin/* 修改后 123[remote &quot;origin&quot;] url = git@github.com:xxx.git fetch = +refs/heads/*:refs/remotes/origin/*","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"}]},{"title":"ubuntu server 16 wifi连接设置","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/ubuntu-server-16-wifi连接设置/","text":"ubuntu server 16 wifi连接设置 安装驱动 12(需要安装aptitude)aptitude install firmware-iwlwifi 加载驱动 1modprobe iwl3945 安装需要的软件包 1apt-get install wireless-tools wpasupplicant 配置无线网络 1vi /etc/network/interfaces 123456auto wlan0iface wlan0 inet dhcppre-up ip link set wlan0 uppre-up iwconfig wlan0 essid ssidwpa-ssid ssidwpa-psk password 启用无线网线1ifup -v wlan0","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"}]},{"title":"ubuntu设置root密码，可ssh登陆","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/ubuntu设置root密码，可ssh登录/","text":"1 添加root用户密码1sudo passwd root 2 设置root用户可ssh登录1vi /etc/ssh/sshd_config 找到1PermitRootLogin without-password /- 改为1PermitRootLogin yes 重启ssh1service ssh restart","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"}]},{"title":"爬取不同分辨率下的不同地图图片数据","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/爬取不同分辨率下的不同地图图片数据/","text":"爬取不同分辨率下的不同地图图片数据12345678910111213141516171819202122232425262728293031323334353637from math import *import urllibimport urllib2import requestsimport osurl_list=[]# 生成url,如/8/0/0.png,8/0/1.png.../8/0/255.png.../8/255/255.pngdef create_url(first,second): for y in range(int(pow(2,second))): for z in range(int(pow(2,second))): url_list.append(str(first)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos;) print str(first)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos; return url_list# 生成url对应的目录def create_dirs(url_list,base_filepath): for x in url_list: x = x.split(&apos;/&apos;) file_path = base_filepath + str(x[0]) + &apos;/&apos; + str(x[1])+&apos;/&apos; if not os.path.exists(file_path): print file_path os.makedirs(file_path)base_url = &apos;http://a.tile.openstreetmap.org/&apos;# 图片下载def download_png(url_list,filepath): for x in url_list: url = base_url + x urllib.urlretrieve(url, filename=&apos;d:/test/&apos;+x) # data = f.read() # with open(filepath + x, &quot;wb+&quot;) as code: # code.write(data)url_list=create_url(8,8)download_png(url_list,&apos;d:/test/&apos;)#create_dirs(url_list,&apos;d:/test/&apos;) 用法 先修改文件路径，分辨率等参数 然后先注释掉download_png函数调用，先调用create_dirs函数创建目录，然后取消注释开始下载图片 采用多进程爬取，并处理网络带来的IOError1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495from math import *import urllibimport urllib2import requestsimport osfrom exceptions import IOErrorimport loggingimport logginglogging.basicConfig(level=logging.WARNING, format=&apos;%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s&apos;, datefmt=&apos;%a, %d %b %Y %H:%M:%S&apos;, filename=&apos;myapp.log&apos;, filemode=&apos;w&apos;)url_list=[]filepath = &apos;d:/test/&apos;base_url = &apos;http://a.tile.openstreetmap.org/&apos;def create_url(start,rate): for y in range(start,int(pow(2,rate))): for z in range(int(pow(2,rate))): url_list.append(str(rate)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos;) logging.warning(str(rate)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos;) return url_listdef create_dirs(url_list,base_filepath): for x in url_list: x = x.split(&apos;/&apos;) file_path = base_filepath + str(x[0]) + &apos;/&apos; + str(x[1])+&apos;/&apos; if not os.path.exists(file_path): logging.warning(file_path) os.makedirs(file_path)def download_png(url_list,filepath): for x in url_list: try: url = base_url + x print url logging.warning(url) urllib.urlretrieve(url, filename=filepath+x) except IOError as serr: logging.error(serr) time.sleep(180) urllib.urlretrieve(url, filename=filepath+x)import multiprocessingimport timedef worker_1(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_2(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_3(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_4(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_5(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_5(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)if __name__ == &quot;__main__&quot;: p1 = multiprocessing.Process(target = worker_1, args = (630,10)) p2 = multiprocessing.Process(target = worker_2, args = (700,10)) p3 = multiprocessing.Process(target = worker_3, args = (800,10)) p4 = multiprocessing.Process(target = worker_4, args = (900, 10)) p5 = multiprocessing.Process(target = worker_5, args = (1000, 10)) p1.start() p2.start() p3.start() p4.start() p5.start()","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://w940853815.github.io/tags/爬虫/"}]},{"title":"seafile磁盘空间满了解决办法","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/seafile磁盘空间满了解决办法/","text":"seafile磁盘空间满了解决办法磁盘扩容（虚拟机）参考：http://www.linuxidc.com/Linux/2012-07/65646.htm 物理机添加一块新的硬盘，原理相同 1fdisk -l :打印当前的磁盘分区表,可以看到新的磁盘加了进来 分区 1234fdisk /dev/sda “sda就是经过扩容的硬盘，为SCSI硬盘，IDE类型硬盘对应为hda，是对该硬盘进行操作n &quot; 命令n用于添加新分区&quot;p &quot; 选择创建主分区&quot;,然后选择分区编号3,4（主分区）w &quot;保存所有并退出，分区划分完毕&quot; 我们在这里是要添加一个新分区，即将扩容出来的那部分做成一个新分区，这样才能被操作系统挂载识别。 此时，fdisk会让你选择添加为逻辑分区呢（编号从5开始）还是主分区（编号1到4）。选择主分区吧，则键入p；选择逻辑分区键入l 此时，fdisk会让你选择主分区的编号，如果已经有了主分区sda1，sda2，那么编号就选3，即要创建的该分区为sda3.键入：3 此时，fdisk又会让你选择该分区的开始值这个就是分区的Start 值（start cylinder）；这里最好直接按回车，如果您输入了一个非默认的数字，会造成空间浪费 此时键入：w “保存所有并退出，分区划分完毕” 格式化 格式化该新添加的分区1mkfs -t ext3 /dev/sda3 磁盘挂载手动挂载，则键入：mount /dev/sda3 /home/work/ “表示将该新分区挂载到/home/work/这个目录下面” 开机自动挂载，则修改/etc/fstab文件，在这个文件里面添加一行：1/dev/sda4 /seafile-data ext3 defaults 0 1 创建符号链接 参考：https://bbs.seafile.com/t/seafile/71)(http://www.cnblogs.com/findumars/p/5747904.html)123cp -r /home/sysadmin/haiwen/seafile-data /seafile-data#当前目录 /home/sysadmin/haiwen/ln -s /seafile-data/ ./seafile-data 总结服务器上一定要慎用rm命令！！！！！！！","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"},{"name":"seafile","slug":"seafile","permalink":"https://w940853815.github.io/tags/seafile/"}]},{"title":"postgresql数据的导入和导出","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/postsql数据的导入和导出/","text":"数据导出PostgreSql在windows安装路径/bin目录下自带Pg_dump.exe执行程序 执行过程： 打开windows下的命令窗口：开始-&gt;cmd-&gt;安装数据库的目录-&gt;进入bin目录； 导出命令： 1pg_dump –h localhost –U db_username –p 5432 –d db_name –f “D:/test.dmp” 参数列表1234567-h：服务器地址；-p：端口号；-U：这里的“U”要大写；-d：数据库名称；-f：文件输出的目录和名称；可选参数-s, --schema-only 只转储模式,不包括数据（导出表结构） 按回车执行，会让输入口令（即数据库用户密码），输入即可，以上命令是输出数据库的全部对象，包含数据，对象(index，table，sequence，function等),但是不包含blob的大对象，如果需要导出大对象那么需要加上“-b”； 导入数据恢复数据：因为导出的是明文数据文件，一次使用psql命令，如：1psql -h localhost -U db_username -d db_name -f &quot;D:\\test.dmp&quot; 这边的-d后面的数据库名称即是需要导入的数据库。同样需要输入数据库密码。并且-d 后面数据库必须为已经存在的数据库补充 导出数据库：方式一：pg_dump -U postgres -f c:\\db.sql postgis方式二：pg_dump -U postgres postgis &gt; c:\\db.sql 导入数据库：方式一：psql -d postgis -f c:\\db.sql postgres 导出具体表：方式一：pg_dump -Upostgres -t mytable -f dump.sql postgres 导入具体表：方式一：psql -d postgis -f c:\\ dump.sql postgres","tags":[{"name":"数据库","slug":"数据库","permalink":"https://w940853815.github.io/tags/数据库/"}]}]