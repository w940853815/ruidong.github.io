[{"title":"解决openvas中提到的\"SSH Weak Encryption Algorithms Supported\"问题","date":"2020-06-03T07:18:19.396Z","path":"2020/06/03/SSH Weak Encryption Algorithms Supported/","text":"错误描述Summary The remote SSH server is configured to allow weak encryption algorithms. Vulnerability Detection Result 123456789101112131415161718The following weak client-to-server encryption algorithms are supported by the remote service:3des-cbcaes128-cbcaes192-cbcaes256-cbcblowfish-cbccast128-cbcThe following weak server-to-client encryption algorithms are supported by the remote service:3des-cbcaes128-cbcaes192-cbcaes256-cbcblowfish-cbccast128-cbc Solution Solution type: Disable the weak encryption algorithms. 解决方案1.备份sshd_config文件 1cp /etc/ssh/sshd_config /etc/ssh/sshd_config.$(date +%F) 2.在/etc/ssh/sshd_config文件中加入下面内容1Ciphers aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,chacha20-poly1305@openssh.com 3.重启ssh服务 1service ssh restart 4.测试是否成功，客户端连接服务器 1ssh root@host -c aes128-cbc 提示Unable to negotiate with {host} port 22: no matching cipher found. Their offer: aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,chacha20-poly1305@openssh.com则修改成功","tags":[{"name":"ssh","slug":"ssh","permalink":"https://w940853815.github.io/tags/ssh/"}]},{"title":"ubuntu查看磁盘raid信息","date":"2020-04-24T02:18:23.664Z","path":"2020/04/24/ubuntu查看磁盘raid信息/","text":"本文主要介绍的是使用硬件作的磁盘raid，如何查看磁盘raid信息，服务器使用的是dell服务器，系统是ubuntu16 查看服务器硬盘信息1cat /proc/scsi/scsi 终端输出 123456789Host: scsi0 Channel: 02 Id: 00 Lun: 00 Vendor: DELL Model: PERC H330 Mini Rev: 4.27 Type: Direct-Access ANSI SCSI revision: 05Host: scsi0 Channel: 02 Id: 01 Lun: 00 Vendor: DELL Model: PERC H330 Mini Rev: 4.27 Type: Direct-Access ANSI SCSI revision: 05Host: scsi10 Channel: 00 Id: 00 Lun: 00 Vendor: HL-DT-ST Model: DVD+-RW GTA0N Rev: A3C0 Type: CD-ROM ANSI SCSI revision: 05 可以看出我们使用的dell的raid卡 下载软件下载perccli_7.3-007.0318_linux.tar.gz文件并解压https://www.dell.com/support/home/cn/zh/cnbsd1/drivers/driversdetails?driverid=52r3d 对于ubuntu系统，需要通过alien安装rpm软件包 123sudo apt-get install aliensudo alien my_package.rpmsudo dpkg -i my_package.deb 切换目录 1cd /opt/MegaRAID/perccli 运行命令查看信息（使用root用户）,其中就有磁盘的raid信息 1./perccli /c0 show #cX 指定控制器，其中 X 是控制器索引 123456---------------------------------------------------------------DG/VD TYPE State Access Consist Cache Cac sCC Size Name ---------------------------------------------------------------0/0 RAID0 Optl RW Yes NRWTD - OFF 237.875 GB 1/1 RAID5 Optl RW Yes NRWTD - OFF 2.181 TB --------------------------------------------------------------- 参考https://www.dell.com/support/article/zh-cn/sln283135/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8poweredge-raid%E6%8E%A7%E5%88%B6%E5%99%A8-perc-%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%95%8C%E9%9D%A2-cli-%E5%AE%9E%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%AE%A1%E7%90%86raid%E6%8E%A7%E5%88%B6%E5%99%A8?lang=zh","tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://w940853815.github.io/tags/ubuntu/"},{"name":"raid","slug":"raid","permalink":"https://w940853815.github.io/tags/raid/"}]},{"title":"nginx匹配多个url配置","date":"2020-04-08T10:51:45.394Z","path":"2020/04/08/nginx匹配多个url配置/","text":"需求场景nignx转发的服务想要开启basic auth认证，后端某些不需要认证的页面不太想被人访问，所以先要通过basic auth认证，才能通过登录界面登录到系统中，可以减少一些潜在的攻击吧。 但很多路由需要后端验证，需要这些路有要写到nginx中，希望匹配到这些路有走后端服务的验证，而不走basic auth认证 htpasswd安装centos1yum install -y httpd-tools ubuntu1apt-get install apache2-utils 配置BASIC_AUTH生成用户名密码1htpasswd -c -d /etc/nginx/passwd.d/admin_passwd admin nginx.conf完整配置示例123456789101112131415161718192021222324252627server &#123; listen 8200; client_max_body_size 500M; # 统一开启认证 auth_basic \"login\"; auth_basic_user_file /etc/nginx/passwd.d/admin_passwd; # 正则匹配关键字为api和static location ~ /.*[api|static]/ &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://xxxxx; auth_basic off; #将认证关掉，采用flask后端认证 &#125; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://xxx; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; 根据url正则进行匹配，除api，static路由都进行basic_auth认证，再增加 location ~ /.[api|static]/这里增加到[]里即可 location ~ /.[api|static|xxxx]/","tags":[{"name":"nginx","slug":"nginx","permalink":"https://w940853815.github.io/tags/nginx/"}]},{"title":"html定时切换图片代码","date":"2020-04-04T05:06:29.470Z","path":"2020/04/04/html自动定时切换图片代码/","text":"本代码会根据2020-06-01与当前时间相差天数选取对应的图片图片文件目录如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\" /&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"&gt; &lt;title&gt;title&lt;/title&gt; &lt;style&gt; #web_bg &#123; position: fixed; top: 0; left: 0; width: 100%; height: 100%; min-width: 1500px; z-index: -10; zoom: 1; background-color: #fff; background-repeat: no-repeat; background-size: cover; -webkit-background-size: cover; -o-background-size: cover; background-position: center 0; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;!--背景图片--&gt; &lt;div id=\"web_bg\"&gt;&lt;/div&gt; &lt;!--其他代码 ... --&gt;&lt;/body&gt;&lt;script&gt; // 提前加载缓存，防止闪屏 for (let index = 1; index &lt; 60; index++) &#123; let img = new Image(); img.src = \"imgs/\" + index + \".png\"; img.onload = function () &#123; document.getElementById(\"web_bg\").style = \"background-image: url(\" + img.src + \")\" &#125; &#125; function changeImg() &#123; var i = 0; var end = new Date('2020-06-01'); console.log(end) var start = new Date() interval = (end - start) / (24 * 3600 * 1000) console.log(parseInt(interval)) var i = parseInt(interval) + 1 let img = new Image(); img.src = \"imgs/\" + i + \".png\"; img.onload = function () &#123; document.getElementById(\"web_bg\").style = \"background-image: url(\" + img.src + \")\" &#125; &#125; // 一分钟刷新一次 setInterval(\"changeImg()\", 1000 * 60);&lt;/script&gt;&lt;/html&gt;","tags":[{"name":"code","slug":"code","permalink":"https://w940853815.github.io/tags/code/"}]},{"title":"本地磁盘，外接网络存储问题","date":"2020-04-01T09:44:19.656Z","path":"2020/04/01/本地磁盘，外接网络存储问题/","text":"本文服务器均为ubtuntu16 问题机房服务器要停电检修，服务器会断电，检修完后，发现几台服务器ssh登录不了，但可以ping通服务器，所以去机房排查问题，发现服务器没正常启动，卡在下图这里 服务器上磁盘挂载信息都记录在/etc/fstab中，包括外接网络存储，这样磁盘出问题，操作系统就无法正常启动了 解决办法除了系统盘的挂载信息/etc/fstab,其余磁盘挂载信息放在/etc/rc.local文件中,在末尾添加即可，使用mount挂载磁盘 12mount /dev/sdb1 /datamount UUID=378fcd7d-5bcc-4c5e-9dfa-ad3561acdb5e /bigdata 这样外接磁盘出问题就不会影响操作系统启动了","tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://w940853815.github.io/tags/ubuntu/"},{"name":"存储","slug":"存储","permalink":"https://w940853815.github.io/tags/存储/"}]},{"title":"ros设置定时ping任务","date":"2020-03-23T04:13:00.145Z","path":"2020/03/23/ros设置定时ping任务/","text":"本文ros型号CCR1072-1G-8S+ 系统版本 RouterOS 6.44 现在需要让路由器始终保持有流量，不然会断线，所以现在设置一个定时ping任务，定时去ping114.114.114.114，让路由器每5分钟访问一下外网，保持流量 使用winbox登录到路有器后，在Tools菜单下有个Netwatch工具，点击左上角➕，新建一条记录 这样就设置好了，点击应用即可","tags":[{"name":"network","slug":"network","permalink":"https://w940853815.github.io/tags/network/"},{"name":"ros","slug":"ros","permalink":"https://w940853815.github.io/tags/ros/"}]},{"title":"git设置socket5代理","date":"2020-01-31T07:31:08.642Z","path":"2020/01/31/git设置sock5代理/","text":"过年在家里，发现github提交代码提交不了，总是失败，pinggithub.com域名不通，于是想对github仓库设置socket5代理，设置如下: 在你仓库目录下执行 1git config --global https.proxy 'socks5://127.0.0.1:1080' 注意先执行git remote -v看你的终端输出什么，我这里远端URL地址使用的是https方式，设置完成后就可以正常更新仓库代码了，速度也快了许多 补充修改上述命令是针对全局的，其它仓库也是使用该代理 如果要取消使用git config --global --edit编辑配置文件删除对应字段即可 本文参考https://gist.github.com/laispace/666dd7b27e9116faece","tags":[{"name":"socket5","slug":"socket5","permalink":"https://w940853815.github.io/tags/socket5/"},{"name":"proxy - git","slug":"proxy-git","permalink":"https://w940853815.github.io/tags/proxy-git/"}]},{"title":"ubuntu双网卡配置","date":"2020-01-16T07:42:02.712Z","path":"2020/01/16/ubuntu双网卡配置/","text":"服务器在两个内网环境中，一个为192.168.1.0/24，一个10.0.0.1/24，需要访问这两个网段中的服务器 一开始修改配置/etc/network/interfaces文件 1234567891011auto enp4s0f0iface enp4s0f0 inet staticaddress 192.168.1.2netmask 255.255.255.0gateway 192.168.1.1auto enp4s0f1iface enp4s0f1 inet staticaddress 10.0.0.2netmask 255.255.255.0gateway 10.0.0.1 重启网络服务service networking restart失败，一个服务器不能有两个网关，也尝试过使用其中一个网关，但另一个网段的地址就无法访问了，后面的解决办法是不设置网关参数，在/etc/network/interfaces文件添加路由，配置如下 12345678910111213auto enp4s0f0iface enp4s0f0 inet staticaddress 192.168.13.2netmask 255.255.255.0#gateway 192.168.13.1auto enp4s0f1iface enp4s0f1 inet staticaddress 210.27.169.25netmask 255.255.255.0#gateway 210.27.169.254up route add -net 10.0.0.0 netmask 255.255.255.0 gw 10.0.0.1 dev enp4s0f1up route add -net 192.168.1.0 netmask 255.255.255.0 gw 192.168.1.1 dev enp4s0f0 要访问哪个网断，添加对应的路由即可，dev后面的参数为网卡名称，up route add -net 10.0.0.0 netmask 255.255.255.0 gw 10.0.0.1 dev enp4s0f1这条路由的意思是访问10.0.0.0./24网段的地址数据包都通过网卡enp4s0f1出去 service networking restart命令重启网络前（重启发现之前的ip配置信息还存在，结果造成一些测试问题），会先执行ip addr flush dev enp4s0f1命令，该命令会清除网卡接口配置信息包括该网卡相关的路由信息，该命令要慎用，如果是远程执行会导致断网！请读者注意 修改配置文件之前也可以使用route add命令添加临时路由测试网络，测试好了再修改/etc/network/interfaces文变成永久路由","tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://w940853815.github.io/tags/ubuntu/"},{"name":"network","slug":"network","permalink":"https://w940853815.github.io/tags/network/"}]},{"title":"使用docker-compose启动多个flask实例，nginx作负载均衡","date":"2020-01-02T06:06:28.274Z","path":"2020/01/02/docker-compose_scale_flask_app_instances/","text":"docker-compose.yml例子1234567891011121314version: \"3\"services: db: image: postgres:latest environment: POSTGRES_USER: postgres POSTGRES_PASSWORD: postgres flask_app: image: \"flask_app/flask_app:latest\" depends_on: - db ports: - \"5000:5000\" 如果按照上面的docker-compose.yml配置文件，我们只能启动一个flask实例，无法使用docker-compose up scale=2启动多个，会提示Bind for 0.0.0.0:5000 failed: port is already allocated错误 如果将14行的配置改为- “5000”,docker-compose启动映射到主机端口又是随机的，需要执行docker-compose ps才能看到映射到主机的端口号 为了在不需要知道flask实例映射到主机的随机端口号，使用nginx作负载均衡 nginx.conf12345678910111213user nginx;events &#123; worker_connections 1000;&#125;http &#123; server &#123; listen 80; location / &#123; proxy_pass http://flask_app:5000; &#125; &#125;&#125; 这里通过docker内部的dns解析服务，它将使用循环实现来根据服务名称解析DNS请求，并将其分发到Docker容器。ngxin反向代理访问flask容器内部的5000端口，就不需要知道映射到主机的随机端口了 docker-compose.yml完整例子12345678910111213141516171819202122version: \"3\"services: db: image: postgres:latest environment: POSTGRES_USER: postgres POSTGRES_PASSWORD: postgres flask_app: image: \"flask_app/flask_app:latest\" depends_on: - db expose: - \"5000\" nginx: image: nginx:latest volumes: - ./nginx.conf:/etc/nginx/nginx.conf:ro depends_on: - flask_app ports: - \"80:80\" 这样就可以任意增加flask实例的数量了 1docker-compose up --scale flask_app=5 压力测试 启动8个flask实例压力测试 Label # 样本 平均值 最小值 最大值 标准偏差 异常 % 吞吐量 接收 KB/sec 发送 KB/sec 平均字节数 HTTP Request 12053 600 10 3940 331.77 0.83% 138.10528 267.96 102.18 1986.8 总体 12053 600 10 3940 331.77 0.83% 138.10528 267.96 102.18 1986.8 启动1个flask实例 Label # 样本 平均值 最小值 最大值 标准偏差 异常 % 吞吐量 接收 KB/sec 发送 KB/sec 平均字节数 HTTP Request 9514 1041 4 18758 797.87 1.05% 83.50375 162.12 61.65 1988 总体 9514 1041 4 18758 797.87 1.05% 83.50375 162.12 61.65 1988 明显启动多个flask实例，吞吐量会跟高些","tags":[{"name":"docker-compose","slug":"docker-compose","permalink":"https://w940853815.github.io/tags/docker-compose/"},{"name":"flask","slug":"flask","permalink":"https://w940853815.github.io/tags/flask/"},{"name":"Nginx","slug":"Nginx","permalink":"https://w940853815.github.io/tags/Nginx/"}]},{"title":"2019已读书籍(6-12月)","date":"2019-12-30T02:21:10.930Z","path":"2019/12/30/2019已读书籍/","text":"6月霍乱时期的爱情（加西亚·马尔克斯） 未来世界的幸存者（阮一峰） 富爸爸，穷爸爸（罗伯特・T・清崎 / 莎伦・L・莱希特） 前方的路（阮一峰） 动物农场（ 乔治·奥威尔） 7月经济学原理（N·格里高利·曼昆） 万历十五年(黄仁宇) 1984( 乔治·奥威尔) 8月黑客与画家（保罗·格雷厄姆） 追风筝的人(卡勒德·胡赛尼) 送你一颗子弹(刘瑜) 房思琪的初恋乐园(林奕含) 9月殡葬人手记（托马斯·林奇） 断舍离(山下英子) 那些伤不起的年轻人(二白) 愿所有相遇，都恰逢其时(DTT) 10月Redis实战（Redis in action）（ Josiah L. Carlson） 如何阅读一本书(莫提默·J. 艾德勒 / 查尔斯·范多伦) 宿命(东野圭吾) 变身(东野圭吾) 11月 ###树上的男爵（卡尔维诺） JavaScript高级程序设计（第3版）(尼古拉斯·泽卡斯) 他们最幸福(大冰) 柑橘与柠檬啊(麦克·莫波格) 12月全球通史（斯塔夫里阿诺斯） 牛虻( 伏尼契) 皮囊( 蔡崇达) 寂寞的游戏( 袁哲生)","tags":[{"name":"书籍","slug":"书籍","permalink":"https://w940853815.github.io/tags/书籍/"}]},{"title":"celery autoreload when code change","date":"2019-12-13T08:52:42.577Z","path":"2019/12/13/代码改动celery自动重启/","text":"当调试celery相关的代码时，每次改完代码，都需要重启celery代码才可以生效，本文的目的就是当代码发生改动，celery可以自动重启,示例代码task.py如下（注：请根据自己的业务逻辑自行修改）12345678910111213from celery import Celeryapp=Celery(\"tasks\", backend=\"redis://127.0.0.1:6379/1, broker=\"redis://127.0.0.1:6379/1\")@app.taskdef add(x,y): return x+y if __name__ == \"__main__\": from werkzeug._reloader import run_with_reloader # 开发时可以直接运行python tasks.py 当前目录下文件改动时，celery会自动重启 run_with_reloader(app.worker_main) 示例代码主要用到了werkzeug库的run_with_reloader函数实现了celery自动重启","tags":[{"name":"celery","slug":"celery","permalink":"https://w940853815.github.io/tags/celery/"}]},{"title":"解决es查询索引不存在导致404问题","date":"2019-12-06T08:37:28.660Z","path":"2019/12/06/解决es查询索引不存在导致404问题/","text":"问题 但查询http://localhost:9100/index1,index2,index3/_search某个索引不存在时，就会出错 1elasticsearch.exceptions.NotFoundError: TransportError(404, 'index_not_found_exception', 'no such index') 解决办法 项目使用的是elasticsearch库,在使用search函数时，添加一个param参数，代码如下 1234567from elasticsearch import Elasticsearches = Elasticsearch(api, http_auth=http_auth)# body,index分别查询体，索引es_index='index1,index2,index3'body=&#123;&#125;params = &#123;\"ignore_unavailable\": \"true\"&#125;result = es.search(index=es_index, body=body, params=params) 这样就会忽略索引不存在的问题，不会报404了 如果使用requests库或者类似postman接口请求工具请求es数据时，可以在url后加?ignore_unavailable=true参数即可忽略索引不存在错误 1http://localhost:9100/index1,index2,index3/_search?ignore_unavailable=true","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://w940853815.github.io/tags/ElasticSearch/"}]},{"title":"Python求某个数值所在的区间","date":"2019-12-02T02:01:02.451Z","path":"2019/12/02/Python求某个数值所在的区间/","text":"求一个数值在哪个区间，可以使用python-intervals来实现 安装 1pip install python-interval 示例代码12345678910111213import intervals as IREP_RES_DES_MAP = I.IntervalDict()REP_RES_DES_MAP_CONFIG = &#123; I.closedopen(-7, 0): 'A', I.closedopen(-14, -7): 'B', I.closedopen(-I.inf, -14): 'C', I.closedopen(0, 2): 'D', I.closedopen(2, 3): 'E', I.closedopen(3, I.inf): 'F',&#125;for key, value in REP_RES_DES_MAP_CONFIG.items(): REP_RES_DES_MAP[key] = value 这样的话，比如REP_RES_DES_MAP[-10]得到的值就会是’B’，不用写大量的if,elif,else作判断，其中I.inf表示无穷大，-I.inf表示负无穷大","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]},{"title":"jenkins初步使用","date":"2019-11-04T02:27:54.796Z","path":"2019/11/04/jenkins初步使用/","text":"之前完成一个功能或修复一个bug，测试环境每次都是登录的服务器，手动执行命令去更新代码，重启服务，一天可能会进行好几次这样的操作，所以想要使用jenkins来实现部署自动化 安装安装环境123CentOS7jdk 1.8Jenkins 2.190.2 安装步骤安装按照官网文档应该就可以了，官方文档链接，本文下载的是war包，执行以下命令启动jenkins 1java -jar jenkins.war --daemon --httpPort=8080 --logfile=/root/jenkins.log 加–daemon参数，可以让Jenkins后台执行 配置jenkins初始化问题安装初始化的插件时，可能会遇到配置代理的问题，在浏览器输入{jenkins服务地址/pluginManager/advanced ​ 将图中的参数https换成http,然后再回到初始话插件的页面，如果还是遇到之前的问题，多试几次就可以了，笔者也是试了很多次才安装好 配置ssh远程执行命令因为jenkins运行的机器和构建的机器不在同一台机器，所以这里用到了jenkins的插件远程执行build命令 在jenkins-&gt;插件管理中安装 SSH plugin插件和Coding Webhook Plugin 配置凭据 在jenkins-&gt;凭据里新建一个凭据，这里主要需要填构建机器私钥，即cat ~/.ssh/id_rsa中的内容，填完保存 在Manager Jenkins-&gt;Configure System-&gt;SSH remote hosts中新建一个配置,填好保存 然后新建一个任务,主要设置两个地方，coding这里WebHook令牌需要在coding里设置一下（需要管理员权限） 在构建选项中选择Execute shell script on remote host using ssh,选择之前配置的机器和填需要之行的命令,填完保存就可以了 到这里基本完成，可以自动化构建系统了，还是方便了很多","tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://w940853815.github.io/tags/jenkins/"},{"name":"ci","slug":"ci","permalink":"https://w940853815.github.io/tags/ci/"}]},{"title":"ubuntu16搭建本地apt源","date":"2019-10-24T03:33:58.626Z","path":"2019/10/24/ubuntu16搭建本地apt源/","text":"本文服务器环境Ubuntu 16.04.3 LTS,因为一些特殊业务原因，有些服务器需不能上外网，服务器安装一些软件包特别麻烦，需要下载软件的deb和软件依赖的deb包，有时下载不全deb包，安装软件就会失败，所以需要在内网环境搭建一个apt源，这样就可以使用apt自动解决一些软件包的依赖。 安装apt-mirror1apt-get install apt-mirror 配置mirror.list文件可根据服务器网络环境选择合适的下载线程数和apt镜像源,因为服务器在清华，所以选择清华镜像源（150G文件一个小时就同步完了）1234567891011# 镜像文件下载地址set base_path /data/apt-mirror# 下载线程数set nthreads 20set _tilde 0deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverseclean http://mirrors.tuna.tsinghua.edu.cn/ubuntu 文件配置完成后，执行apt-mirror开始同步，因为同步时间比较长，笔者使用tmux,建立一个session，然后执行命令，或者使用nohup命令放到后台执行 配置nginx（配置HTTP访问）更改/etc/nging/nginx.conf文件，加以下配置123456789101112server &#123; listen 80; # 显示目录 autoindex on; location / &#123; index index.html index.htm; # 这里填写镜像保存位置 root /data/apt-mirror; &#125; access_log /var/log/nginx/localhost.log;&#125; 更改完配置，先测试配置，如果测试通过，则重新加载nginx配置文件 12nginx -tnginx -s reload 客户端配置编辑/etc/apt/source.list文件（可以先备份一下），ip和端口级网站目录结构需要根据自己的配置修改 1234deb [arch=amd64] http://127.0.0.1:81/mirror/mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiversedeb [arch=amd64] http://127.0.0.1:81/mirror/mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiversedeb [arch=amd64] http://127.0.0.1:81/mirror/mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiversedeb [arch=amd64] http://127.0.0.1:81/mirror/mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse 以上客户端配置也多添加了[arch=amd64]，用于指定架构，否则会出现 123Err http://127.0.0.1:81 trusty/main i386 Packages 404 Not Found... 最后执行,更新成功就可以安装需要的软件了 1apt-get update","tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://w940853815.github.io/tags/ubuntu/"},{"name":"apt","slug":"apt","permalink":"https://w940853815.github.io/tags/apt/"}]},{"title":"后面要做的事情","date":"2019-10-22T10:44:13.338Z","path":"2019/10/22/立flag/","text":"好久没刷leetcode了，觉得自己刷起来很吃力，去看算法书，结果算法书也读着也吃劲，结果就没再刷了，今天看了一位大佬的博客，发现进大厂都是在考算法，觉着应该还是要多学习算法，不能让自己待在舒适区，自己还年轻，趁着年轻，还学的动，不能每天只是curd 给自己定个刷算法计划： 每周至少三个算法，无上限 算法书继续读（一周一章？）","tags":[{"name":"idea","slug":"idea","permalink":"https://w940853815.github.io/tags/idea/"},{"name":"leetcode","slug":"leetcode","permalink":"https://w940853815.github.io/tags/leetcode/"}]},{"title":"ERROR-No-compiler-is-provided-in-this-environment.-Perhaps-you-are-running-on-a-JRE-rather-than-a-JDK","date":"2019-10-21T10:34:51.182Z","path":"2019/10/21/[ERROR]No_compiler_is_provided_in_this_environment_Perhaps_you_are_running_on_a_JRE_rather_than_a_JDK/","text":"mvn install时报错No compiler is provided in this environment. Perhaps you are running on a JRE rather than a JDK?1234567root@ruidong:~/dcm4che# mvn -vApache Maven 3.3.9Maven home: /usr/share/mavenJava version: 1.8.0_222, vendor: Private BuildJava home: /usr/lib/jvm/java-8-openjdk-amd64/jreDefault locale: en_US, platform encoding: UTF-8OS name: \"linux\", version: \"4.15.0-58-generic\", arch: \"amd64\", family: \"unix\" mvn -v显示Java home后带jre，我以为我JAVA_HOME配置错了，改了下~/.bashrc文件重新配置了JAVA_HOME,结果并未解决问题，问题jdk版本问题，机器装的是java-8-openjdk-amd64,参考链接，重新安装jdk错误解决（系统为ubtuntu16） 1sudo apt-get install openjdk-8-jdk","tags":[{"name":"java","slug":"java","permalink":"https://w940853815.github.io/tags/java/"},{"name":"maven","slug":"maven","permalink":"https://w940853815.github.io/tags/maven/"}]},{"title":"记一次服务器漏洞处理过程（如何删除jar中的文件）","date":"2019-09-10T10:16:57.890Z","path":"2019/09/10/记一次服务器漏洞处理过程/","text":"今天收到邮件，漏洞摘要如下 意思存在一下网站目录下一些markdown文件，漏洞原因：在目录中发现文档文件(例如: readme.txt, changelog.txt, …) 文档文件中可能包含当 前网站程序使用的名称及版本信息，可以帮助 恶意攻击者识别网站应用并攻击网站，应该从 线上服务器删除这些文件。 看到这个以后，想着直接找到文件所在目录，删除就好，但处理过程并没有这么顺利 先查找服务器目录以md为扩展名的文件，结果并未找到 12root@67e088ad8f62:/opt/guacamole# find / | grep -i *.mdroot@67e088ad8f62:/opt/guacamole# 又以jquery，angular等字段查找，发现jar包名和url路径十分相似，推测这些md文件是从jar获得的，所以问了下java的同学同事，确实会这样 1234567root@67e088ad8f62:/opt/guacamole# find / | grep -i jquery/usr/local/tomcat/webapps/guacamole_bak/WEB-INF/lib/jquery-3.3.1.jar/usr/local/tomcat/webapps/guacamole_bak/META-INF/bundled/jquery-3.3.1/usr/local/tomcat/webapps/guacamole_bak/META-INF/bundled/jquery-3.3.1/LICENSE.txt/usr/local/tomcat/webapps/guacamole/WEB-INF/lib/jquery-3.3.1.jar/usr/local/tomcat/webapps/guacamole/META-INF/bundled/jquery-3.3.1/usr/local/tomcat/webapps/guacamole/META-INF/bundled/jquery-3.3.1/LICENSE.txt 想到两个解决办法：a.直接删除jar包中的文件。b.修改tomcat配置，配置文件访问规则，以md为扩展名的文件返回404。b方法找了一会，没发现有这样的配置，所以开始使用a方法，a方法这里使用到jar，zip工具 列出jar包中文件内容 用法: jar {ctxui}[vfmn0PMe] [jar-file] [manifest-file] [entry-point] [-C dir] files …选项: -t 列出档案目录 -v 在标准输出中生成详细输出 -f 指定档案文件名 123456789101112131415➜ lib# jar -tvf angular-module-shim-0.0.4.jar 0 Mon Nov 28 19:02:36 CST 2016 META-INF/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/maven/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/maven/org.webjars.bower/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/maven/org.webjars.bower/angular-module-shim/ 1613 Mon Nov 28 19:02:36 CST 2016 META-INF/maven/org.webjars.bower/angular-module-shim/pom.xml 105 Mon Nov 28 19:02:36 CST 2016 META-INF/maven/org.webjars.bower/angular-module-shim/pom.properties 0 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/ 0 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/0.0.4/ 1078 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/0.0.4/LICENSE 1104 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/0.0.4/README.md 774 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/0.0.4/angular-module-shim.js 543 Mon Nov 28 19:02:36 CST 2016 META-INF/resources/webjars/angular-module-shim/0.0.4/bower.json 找到jar包中包含README.md文件，文件路径和url中一致，所以删除jar中的README.md文件，用到zip命令,不需要解压jar包删除文件后再打成jar包 zipzip [-options] [-b path] [-t mmddyyyy] [-n suffixes] [zipfile list] [-xi list] -d delete entries in zipfile -m move into zipfile (delete OS files) 12➜ lib# zip -d angular-module-shim-0.0.4.jar \"META-INF/resources/webjars/angular-module-shim/0.0.4/README.md\"deleting: META-INF/resources/webjars/angular-module-shim/0.0.4/README.md 最后将处理过的jar上传到服务器，进行替换，发现大部分链接都访问不到，返回404了，但还有3个链接还是返回README.md，确认了好几次jar包已经没有README.md文件，折腾好久，最后想到是不是存在缓存，这里在原先url地址后加 ?a=1,发现链接返回404了，原来是本地浏览器缓存，清掉缓存后，有漏洞的文件都已经处理了，问题解决","tags":[{"name":"java","slug":"java","permalink":"https://w940853815.github.io/tags/java/"},{"name":"local cache","slug":"local-cache","permalink":"https://w940853815.github.io/tags/local-cache/"}]},{"title":"python使用cProfile对脚本进行性能分析","date":"2019-09-05T05:47:24.846Z","path":"2019/09/05/python使用cProfile对脚本进行性能分析/","text":"写者要从oracle数据库导出一些长文本字段的数据，但效率不是太高，导出十多条数据需要2-3分钟，所以想对脚本进行一下性能分析，看脚本导出慢在了哪里，生成的图像文件如下 最后发现时间都花在了oracle查询fetchall函数上，所以后面是因为查询的sql没有使用索引的字段去查，会很慢，使用索引的字段去查，效率提升了 十几倍 这里使用的是 gprof2dot, 可以看到调用次数, 占用时间和百分比信息的图像，比较直观 安装 mac 1brew install gprof2dot Debian/Ubuntu users1apt-get install graphviz 生成图像文件12python3 -m cProfile -o output.pstat test.pygprof2dot -f pstats output.pstat | dot -Tpng -o output.png 执行完，在脚本的目录就会生成图像文件了","tags":[{"name":"数据库","slug":"数据库","permalink":"https://w940853815.github.io/tags/数据库/"},{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"},{"name":"性能分析","slug":"性能分析","permalink":"https://w940853815.github.io/tags/性能分析/"}]},{"title":"es年龄分段统计","date":"2019-08-28T08:19:39.138Z","path":"2019/08/28/es年龄分段统计/","text":"前端最终效果展示 这里需要统计不同年龄段的人数，以10为间隔1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556\"age_ranges\": &#123; \"range\": &#123; \"field\": \"VISIT_AGE\", \"ranges\": [&#123; \"key\": \"0-10\", \"from\": 0, \"to\": 10 &#125;, &#123; \"key\": \"10-20\", \"from\": 10, \"to\": 20 &#125;, &#123; \"key\": \"20-30\", \"from\": 20, \"to\": 30 &#125;, &#123; \"key\": \"30-40\", \"from\": 30, \"to\": 40 &#125;, &#123; \"key\": \"40-50\", \"from\": 40, \"to\": 50 &#125;, &#123; \"key\": \"50-60\", \"from\": 50, \"to\": 60 &#125;, &#123; \"key\": \"60-70\", \"from\": 60, \"to\": 70 &#125;, &#123; \"key\": \"70-80\", \"from\": 70, \"to\": 80 &#125;, &#123; \"key\": \"80-90\", \"from\": 80, \"to\": 90 &#125;, &#123; \"key\": \"90-100\", \"from\": 90, \"to\": 100 &#125; ] &#125;&#125; 查询语句中一开始ranges没有key键，只有{“”from”: 0,”to”: 10”}，这样查询的结果会转成浮点数，如下 1&#123;'buckets': [&#123;'key': '0.0-10.0', 'from': 0.0, 'to': 10.0, 'doc_count': 0&#125;, &#123;'key': '10.0-20.0', 'from': 10.0, 'to': 20.0, 'doc_count': 0&#125;, &#123;'key': '21.0-30.0', 'from': 21.0, 'to': 30.0, 'doc_count': 1&#125;, &#123;'key': '31.0-40.0', 'from': 31.0, 'to': 40.0, 'doc_count': 4&#125;, &#123;'key': '41.0-50.0', 'from': 41.0, 'to': 50.0, 'doc_count': 5&#125;, &#123;'key': '51.0-60.0', 'from': 51.0, 'to': 60.0, 'doc_count': 16&#125;, &#123;'key': '61.0-70.0', 'from': 61.0, 'to': 70.0, 'doc_count': 29&#125;, &#123;'key': '71.0-80.0', 'from': 71.0, 'to': 80.0, 'doc_count': 12&#125;, &#123;'key': '80.0-90.0', 'from': 80.0, 'to': 90.0, 'doc_count': 3&#125;, &#123;'key': '91.0-100.0', 'from': 91.0, 'to': 100.0, 'doc_count': 0&#125;]&#125; 加上key就可以指定返回的key了","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://w940853815.github.io/tags/ElasticSearch/"}]},{"title":"断舍离读书笔记","date":"2019-08-28T07:21:39.838Z","path":"2019/08/28/断舍离/","text":"以自我为中心挑选物品，而不是以物品为中心 一旦通过断舍离提升了自我形象，那么别人就会自然而然地觉得”他生活得那么精致，可不能随便拿个粗陋的东西送他就了事了”。慢慢地，你就会感觉到，周围人对待自己的态度发生了变化。可见，这种筛选物品的工作，也具有改变自己与他人关系的力量","tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://w940853815.github.io/tags/读书笔记/"}]},{"title":"flask_restfule接收多个文件","date":"2019-08-21T03:28:36.000Z","path":"2019/08/21/flask_restful同时接收多个文件/","text":"添加action=’append’即可接受多个文件 12345678910111213@rest_resourceclass Uploads(BaseResource): endpoints = ['/uploads'] @token_auth.login_required def post(self, *args, **kwargs): parser = reqparse.RequestParser() parser.add_argument('file', type=werkzeug.FileStorage,location='files', action='append') args = parser.parse_args() files = args.file # type(files) &gt;&gt;&gt;list for file in files: file.save('file_path') return &#123;'msg': '文件上传成功！'&#125;","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"},{"name":"flask","slug":"flask","permalink":"https://w940853815.github.io/tags/flask/"},{"name":"flask-restful","slug":"flask-restful","permalink":"https://w940853815.github.io/tags/flask-restful/"}]},{"title":"boot failed nfs,welcome to emergency mode","date":"2019-06-20T07:55:12.000Z","path":"2019/06/20/nfs_boot_faild/","text":"问题：机房服务器断电进行消防检查，检查完后服务器远程登录不了去机房查看服务器，服务器启动时出现了 welcome to emergency mode. ...... journalctl -xb... ..... Press enter for maintenance (or type Control-D to continue): --- Ctrl+d继续启动服务器。 按下Ctrl+d 成功启动 因为服务器使用nfs挂载了网络存储，猜测存储服务器还未完全启动，服务器就去挂载网络存储，会找不到，所以服务器出现了上述情况 解决方案1UUID=d9a2b784-4579-4d89-8713-4b7d6b00742b /bigdata ext4 defaults,x-systemd.device-timeout=3 0 0 在/etc/fstab文件中添加了一个选项,x-systemd.device-timeout=3参考) 设置 x-systemd.device-timeout=# 参数，设置超时时间，以防止网络资源不能访问的时候浪费时间 使用以下命令检查fstab是否存在内容错误 1` mount -fav` -f, –fake dry run; skip the mount(2) syscall 表示这只是测试, 并不会真的安装 -a, –all mount all filesystems mentioned in fstab 表示测试所有 /etc/fstab 中的内容 -v, –verbose say what is being done 表示显示尽可能多的 log","tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"https://w940853815.github.io/tags/ubuntu/"}]},{"title":"* No PostgreSQL clusters exist; see 'man pg_createcluster'","date":"2018-09-21T08:55:12.000Z","path":"2018/09/21/No-PostgreSQL-clusters-exist-see-man-pg-createcluster/","text":"Ubuntu14.04 PostgreSQL(9.3)卸载又重装,启动postgresql时会报No PostgreSQL clusters exist; see ‘’man pg_createcluster”错误，解决办法: 1234sudo pg_createcluster 9.3 main --start# 如果是9.5版本sudo pg_createcluster 9.5 main --startsudo service postgresql restart","tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://w940853815.github.io/tags/postgresql/"},{"name":"数据库","slug":"数据库","permalink":"https://w940853815.github.io/tags/数据库/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://w940853815.github.io/tags/ubuntu/"}]},{"title":".gitignore规则不生效","date":"2018-09-21T08:35:17.000Z","path":"2018/09/21/gitignore规则不生效/","text":"gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。 解决方法就是先把本地缓存删除（改变成未track状态），然后再提交: 1git rm -r --cached .","tags":[{"name":"git","slug":"git","permalink":"https://w940853815.github.io/tags/git/"}]},{"title":"TypeError: the JSON object must be str, not 'bytes'","date":"2018-09-21T08:28:42.000Z","path":"2018/09/21/TypeError-the-JSON-object-must-be-str-not-bytes/","text":"res类型是bytes时 1data = json.loads(res) 会报终端错误 1TypeError: the JSON object must be str, not 'bytes' 解决办法 1data = json.loads(res.decode('utf-8')) 好像这个错误和python版本有关系，python3.6不需要decode不会报错，python3.5会报这个错误","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]},{"title":"ModuleNotFoundError: No module named 'kombu.async'","date":"2018-09-21T08:24:51.000Z","path":"2018/09/21/ModuleNotFoundError-No-module-named-kombu-async/","text":"启动celery时报错ModuleNotFoundError: No module named ‘kombu.async’ 解决办法 1pip install -U celery==4.1.1 详情参考issuses #4760","tags":[{"name":"celery","slug":"celery","permalink":"https://w940853815.github.io/tags/celery/"},{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]},{"title":"postgres ERROR permission denied to create database 解决方法","date":"2018-09-13T06:35:52.000Z","path":"2018/09/13/postgres-ERROR-permission-denied-to-create-database-解决方法/","text":"ERROR: permission denied to create database 在mac os x上用brew安装postgresql时 ，它不像linux系统上会默认创建一个postgres的系统用户,可以打开数据库控制台创建数据库 123➜ dmp git:(master) ✗ psql -d postgrespostgres=# create database test;CREATE DATABASE","tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://w940853815.github.io/tags/postgresql/"},{"name":"数据库","slug":"数据库","permalink":"https://w940853815.github.io/tags/数据库/"}]},{"title":"flask_sqlalchemy使用","date":"2018-09-11T14:19:36.000Z","path":"2018/09/11/flask-sqlalchemy使用/","text":"postgresql—flask-sqlalchemy字段对应 Postgresql Flask-sqlachemy varchar2 （有长度） db.Column(db.String(50)) Init db.Column(db.Integer) timestamp db.Column(db.DateTime) varchar2 （无长度） db.Column(db.String) 主键默认使用uuid 1id = db.Column(db.String(64), primary_key=True) 字段不为空 1name = db.Column(db.String(50), nullable=False) 设置外键 1org_id = db.Column(db.String(64), db.ForeignKey('tb_org.org_id')) 创建索引 1name = db.Column(db.String(50), index=True) #注意： 1id = db.Column(db.String(64), primary_key=True, default=uuid.uuid4()) 这样默认值会再添加完一条数据，再次添加一条数据时，会主键id已存在，所以不要采取这种方式，应在插入时生成一个新的uuid，例如： 1tb_u = tb_user(user_id=uuid.uuid4(),user_phone=phone)","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"},{"name":"flask","slug":"flask","permalink":"https://w940853815.github.io/tags/flask/"},{"name":"flask-sqlalchemy","slug":"flask-sqlalchemy","permalink":"https://w940853815.github.io/tags/flask-sqlalchemy/"}]},{"title":"celery使用","date":"2018-09-07T03:58:12.000Z","path":"2018/09/07/celery任务状态/","text":"Celery任务状态 PENDING-&gt;STARTED-&gt;SUCCESS/FAILD “STARTED”状态是一个特殊状态,当task_trace_started配置被设置为True或者@task(track_started=True)选项被设置时才会有出现STARTED状态 PENDING”状态实际上并不是一个记录状态，它是任何未知id的任务的默认状态，下面的例子中会出现这一状态： 123from proj.celery import appres=app.AsyncResult('this-id-does-not-exist')res.state'PENDING' cekery key erro ‘async’错误解决方法 1pip install -U \"celery[redis]\" supervisor配置celery 12345678910111213141516[program:celery]command=/usr/local/bin/celery worker -A tasks --loglevel=infodirectory=&#123;tasks.py文件所在目录&#125;user=rootnumprocs=1;redirect_stderr=true ; redirect proc stderr to stdout (default false)stdout_logfile=/var/log/supervisord/celery.logstderr_logfile=/var/log/supervisord/celery.logautostart=trueautorestart=truestartsecs=10stopwaitsecs = 600killasgroup=truepriority=998stdout_logfile_maxbytes = 20MBstdoiut_logfile_backups = 20","tags":[{"name":"celery","slug":"celery","permalink":"https://w940853815.github.io/tags/celery/"},{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]},{"title":"iview modal控制关闭","date":"2018-09-07T03:44:27.000Z","path":"2018/09/07/iview-modal控制关闭/","text":"使用 iview 的 Modal对话框实现单击确定的时候不直接关闭对话框，而是经过一些判断，满足自己的条件的时候再关闭对话框 使用iview的 slot 自定义样式实现，经过一些业务逻辑判断，可控制modal显示关闭 1234&lt;divslot=&quot;footer&quot;&gt; &lt;Buttontype=&quot;text&quot;size=&quot;large&quot; @click=&quot;modalCancel&quot;&gt;取消Button&gt; &lt;Buttontype=&quot;primary&quot;size=&quot;large&quot; @click=&quot;modalOk&quot;&gt;确定Button&gt;&lt;div&gt;","tags":[{"name":"vue","slug":"vue","permalink":"https://w940853815.github.io/tags/vue/"},{"name":"iview","slug":"iview","permalink":"https://w940853815.github.io/tags/iview/"}]},{"title":"python3基础数据知识整理","date":"2018-09-06T09:04:34.000Z","path":"2018/09/06/python基础数据知识整理/","text":"列表(list)) 字典(dict)) 列表(list)123456789101112# 两个列表相加[1, 2, 3] + [4, 5, 6]# 判断某一元素是否在列表中3 in [1, 2, 3]# 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表）list.extend(seq)# 从列表中找出某个值第一个匹配项的索引位置list.index(obj)# 指定位置将对象插入列表list.insert(index, obj)# 移除列表中某个值的第一个匹配项list.remove(obj) 字典(dict)123456789101112131415161718192021222324252627282930313233343536373839404142434445# dict键必须不可变，所以可以用数字，字符串或元组充当，所以用列表就不行# 删除键是'Name'的条目del dict['Name']# 清空词典所有条目dict.clear()# 删除词典del dict# 计算字典元素个数，即键的总数len(dict)# 创建一个新字典，以序列 seq 中元素做字典的键，val 为字典所有键对应的初始值dict.fromkeys(seq[, val])In [75]: d= dict.fromkeys([1,2,3],['a','b','c'])In [76]: dOut[76]: &#123;1: ['a', 'b', 'c'], 2: ['a', 'b', 'c'], 3: ['a', 'b', 'c']&#125;# 返回指定键的值，如果值不在字典中返回default值dict.get(key, default=None)# 以列表返回一个字典所有的键dict.keys()In [78]: d.keys()Out[78]: dict_keys([1, 2, 3])In [79]: type(d.keys())Out[79]: dict_keysIn [80]: list(d.keys())Out[80]: [1, 2, 3]# 以列表返回字典中的所有值dict.values()In [81]: d.values()Out[81]: dict_values([['a', 'b', 'c'], ['a', 'b', 'c'], ['a', 'b', 'c']])# 删除字典给定键 key 所对应的值，返回值为被删除的值。key值必须给出。 否则，返回default值。pop(key[,default])In [83]: d.pop(1)Out[83]: ['a', 'b', 'c']# 随机返回并删除字典中的一对键和值。popitem()In [84]: d.popitem()Out[84]: (3, ['a', 'b', 'c']) 未完待续…","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"}]},{"title":"hexo搭建本博客","date":"2018-09-05T09:25:36.000Z","path":"2018/09/05/hexo博客搭建/","text":"安装(需要node,git) 1npm install -g hexo-cli 阅读hexo官方文档 https://hexo.io/zh-cn/docs/setup 完成建站，配置，熟悉hexo常用命令用法(init,new,generate,server,deploy) 使用主题 https://github.com/yscoder/hexo-theme-indigo 按照文档说明，换成hexo-theme-indigo主题 修改完配置，主要修改一些个人信息 创建文章 1hexo new post 文章标题 利用hexo发布到xxxx.github.io(hexo deploy) 使用gitment支持评论123456&#123;HEXO_ROOT&#125;/themes/indigo/_config.yml修改配置gitment: owner: xxx # github用户名 repo: xxx.github.io # 不加https client_id: xxx client_secret: xxx 使用gitment插件中间遇到的问题 404 not foundrepo填错，或者owner不对 422 错误向github提交的url参数超过了限制，解决办法http://hheszy.com/2018/03/19/hexo-next-validation-failed-%E6%8A%A5%E9%94%99gitment%E9%85%8D%E7%BD%AEgitment-swig/","tags":[{"name":"hexo","slug":"hexo","permalink":"https://w940853815.github.io/tags/hexo/"}]},{"title":"git ssh key 设置","date":"2018-09-05T08:48:44.000Z","path":"2018/09/05/git-ssh-key-设置/","text":"git ssh key 设置设置完成后，git pull,push等命令就不需要再输入用户名和密码了 生成公钥，私钥1ssh-keygen -t rsa -C &quot;邮箱地址&quot; 然后得到两个文件：私钥id_rsa和公钥id_rsa.pub 把公钥里面的内容复制到gitlab，github的ssh keys设置处 测试 1ssh -T git@主机ip 如果看到Hi后面是你的用户名，就说明成功了。 修改.git文件夹下config中的url 修改前123[remote &quot;origin&quot;] url = https://github.com/xxxx.git fetch = +refs/heads/*:refs/remotes/origin/* 修改后 123[remote &quot;origin&quot;] url = git@github.com:xxx.git fetch = +refs/heads/*:refs/remotes/origin/*","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"}]},{"title":"ubuntu server 16 wifi连接设置","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/ubuntu-server-16-wifi连接设置/","text":"ubuntu server 16 wifi连接设置 安装驱动 12(需要安装aptitude)aptitude install firmware-iwlwifi 加载驱动 1modprobe iwl3945 安装需要的软件包 1apt-get install wireless-tools wpasupplicant 配置无线网络 1vi /etc/network/interfaces 123456auto wlan0iface wlan0 inet dhcppre-up ip link set wlan0 uppre-up iwconfig wlan0 essid ssidwpa-ssid ssidwpa-psk password 启用无线网线1ifup -v wlan0","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"}]},{"title":"爬取不同分辨率下的不同地图图片数据","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/爬取不同分辨率下的不同地图图片数据/","text":"爬取不同分辨率下的不同地图图片数据12345678910111213141516171819202122232425262728293031323334353637from math import *import urllibimport urllib2import requestsimport osurl_list=[]# 生成url,如/8/0/0.png,8/0/1.png.../8/0/255.png.../8/255/255.pngdef create_url(first,second): for y in range(int(pow(2,second))): for z in range(int(pow(2,second))): url_list.append(str(first)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos;) print str(first)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos; return url_list# 生成url对应的目录def create_dirs(url_list,base_filepath): for x in url_list: x = x.split(&apos;/&apos;) file_path = base_filepath + str(x[0]) + &apos;/&apos; + str(x[1])+&apos;/&apos; if not os.path.exists(file_path): print file_path os.makedirs(file_path)base_url = &apos;http://a.tile.openstreetmap.org/&apos;# 图片下载def download_png(url_list,filepath): for x in url_list: url = base_url + x urllib.urlretrieve(url, filename=&apos;d:/test/&apos;+x) # data = f.read() # with open(filepath + x, &quot;wb+&quot;) as code: # code.write(data)url_list=create_url(8,8)download_png(url_list,&apos;d:/test/&apos;)#create_dirs(url_list,&apos;d:/test/&apos;) 用法 先修改文件路径，分辨率等参数 然后先注释掉download_png函数调用，先调用create_dirs函数创建目录，然后取消注释开始下载图片 采用多进程爬取，并处理网络带来的IOError1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495from math import *import urllibimport urllib2import requestsimport osfrom exceptions import IOErrorimport loggingimport logginglogging.basicConfig(level=logging.WARNING, format=&apos;%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s&apos;, datefmt=&apos;%a, %d %b %Y %H:%M:%S&apos;, filename=&apos;myapp.log&apos;, filemode=&apos;w&apos;)url_list=[]filepath = &apos;d:/test/&apos;base_url = &apos;http://a.tile.openstreetmap.org/&apos;def create_url(start,rate): for y in range(start,int(pow(2,rate))): for z in range(int(pow(2,rate))): url_list.append(str(rate)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos;) logging.warning(str(rate)+&apos;/&apos;+str(y)+&apos;/&apos;+str(z)+&apos;.png&apos;) return url_listdef create_dirs(url_list,base_filepath): for x in url_list: x = x.split(&apos;/&apos;) file_path = base_filepath + str(x[0]) + &apos;/&apos; + str(x[1])+&apos;/&apos; if not os.path.exists(file_path): logging.warning(file_path) os.makedirs(file_path)def download_png(url_list,filepath): for x in url_list: try: url = base_url + x print url logging.warning(url) urllib.urlretrieve(url, filename=filepath+x) except IOError as serr: logging.error(serr) time.sleep(180) urllib.urlretrieve(url, filename=filepath+x)import multiprocessingimport timedef worker_1(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_2(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_3(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_4(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_5(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)def worker_5(start,rate): url_list = create_url(start, rate) create_dirs(url_list, filepath) download_png(url_list, filepath)if __name__ == &quot;__main__&quot;: p1 = multiprocessing.Process(target = worker_1, args = (630,10)) p2 = multiprocessing.Process(target = worker_2, args = (700,10)) p3 = multiprocessing.Process(target = worker_3, args = (800,10)) p4 = multiprocessing.Process(target = worker_4, args = (900, 10)) p5 = multiprocessing.Process(target = worker_5, args = (1000, 10)) p1.start() p2.start() p3.start() p4.start() p5.start()","tags":[{"name":"python","slug":"python","permalink":"https://w940853815.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://w940853815.github.io/tags/爬虫/"}]},{"title":"seafile磁盘空间满了解决办法","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/seafile磁盘空间满了解决办法/","text":"seafile磁盘空间满了解决办法磁盘扩容（虚拟机）参考：http://www.linuxidc.com/Linux/2012-07/65646.htm 物理机添加一块新的硬盘，原理相同 1fdisk -l :打印当前的磁盘分区表,可以看到新的磁盘加了进来 分区 1234fdisk /dev/sda “sda就是经过扩容的硬盘，为SCSI硬盘，IDE类型硬盘对应为hda，是对该硬盘进行操作n &quot; 命令n用于添加新分区&quot;p &quot; 选择创建主分区&quot;,然后选择分区编号3,4（主分区）w &quot;保存所有并退出，分区划分完毕&quot; 我们在这里是要添加一个新分区，即将扩容出来的那部分做成一个新分区，这样才能被操作系统挂载识别。 此时，fdisk会让你选择添加为逻辑分区呢（编号从5开始）还是主分区（编号1到4）。选择主分区吧，则键入p；选择逻辑分区键入l 此时，fdisk会让你选择主分区的编号，如果已经有了主分区sda1，sda2，那么编号就选3，即要创建的该分区为sda3.键入：3 此时，fdisk又会让你选择该分区的开始值这个就是分区的Start 值（start cylinder）；这里最好直接按回车，如果您输入了一个非默认的数字，会造成空间浪费 此时键入：w “保存所有并退出，分区划分完毕” 格式化 格式化该新添加的分区1mkfs -t ext3 /dev/sda3 磁盘挂载手动挂载，则键入：mount /dev/sda3 /home/work/ “表示将该新分区挂载到/home/work/这个目录下面” 开机自动挂载，则修改/etc/fstab文件，在这个文件里面添加一行：1/dev/sda4 /seafile-data ext3 defaults 0 1 创建符号链接 参考：https://bbs.seafile.com/t/seafile/71)(http://www.cnblogs.com/findumars/p/5747904.html)123cp -r /home/sysadmin/haiwen/seafile-data /seafile-data#当前目录 /home/sysadmin/haiwen/ln -s /seafile-data/ ./seafile-data 总结服务器上一定要慎用rm命令！！！！！！！","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"},{"name":"seafile","slug":"seafile","permalink":"https://w940853815.github.io/tags/seafile/"}]},{"title":"ubuntu设置root密码，可ssh登陆","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/ubuntu设置root密码，可ssh登录/","text":"1 添加root用户密码1sudo passwd root 2 设置root用户可ssh登录1vi /etc/ssh/sshd_config 找到1PermitRootLogin without-password /- 改为1PermitRootLogin yes 重启ssh1service ssh restart","tags":[{"name":"linux","slug":"linux","permalink":"https://w940853815.github.io/tags/linux/"}]},{"title":"postgresql数据的导入和导出","date":"2018-09-05T08:47:44.000Z","path":"2018/09/05/postsql数据的导入和导出/","text":"数据导出PostgreSql在windows安装路径/bin目录下自带Pg_dump.exe执行程序 执行过程： 打开windows下的命令窗口：开始-&gt;cmd-&gt;安装数据库的目录-&gt;进入bin目录； 导出命令： 1pg_dump –h localhost –U db_username –p 5432 –d db_name –f “D:/test.dmp” 参数列表1234567-h：服务器地址；-p：端口号；-U：这里的“U”要大写；-d：数据库名称；-f：文件输出的目录和名称；可选参数-s, --schema-only 只转储模式,不包括数据（导出表结构） 按回车执行，会让输入口令（即数据库用户密码），输入即可，以上命令是输出数据库的全部对象，包含数据，对象(index，table，sequence，function等),但是不包含blob的大对象，如果需要导出大对象那么需要加上“-b”； 导入数据恢复数据：因为导出的是明文数据文件，一次使用psql命令，如：1psql -h localhost -U db_username -d db_name -f &quot;D:\\test.dmp&quot; 这边的-d后面的数据库名称即是需要导入的数据库。同样需要输入数据库密码。并且-d 后面数据库必须为已经存在的数据库补充 导出数据库：方式一：pg_dump -U postgres -f c:\\db.sql postgis方式二：pg_dump -U postgres postgis &gt; c:\\db.sql 导入数据库：方式一：psql -d postgis -f c:\\db.sql postgres 导出具体表：方式一：pg_dump -Upostgres -t mytable -f dump.sql postgres 导入具体表：方式一：psql -d postgis -f c:\\ dump.sql postgres","tags":[{"name":"数据库","slug":"数据库","permalink":"https://w940853815.github.io/tags/数据库/"}]}]